{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family=fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()) # for Windows OS user\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from tensorflow import keras\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = pd.read_csv(os.path.abspath(\"../input\")+'/X_test.csv', encoding='cp949')\n",
    "IDtest = tst.custid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 우리가 직접 진행한 feature engineering\n",
    "X_train_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_train_select_hj.csv', encoding='cp949')\n",
    "X_test_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_test_select_hj.csv', encoding='cp949')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 1등팀 feature selection by shap\n",
    "X_train_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_train_shap_1st.csv', encoding='cp949')\n",
    "X_test_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_test_shap_1st.csv', encoding='cp949')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 2등팀 feature selection by shap\n",
    "X_train_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_train_shap_2nd.csv', encoding='cp949')\n",
    "X_test_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_test_shap_2nd.csv', encoding='cp949')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 3등팀 feature selection by shap\n",
    "X_train_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_train_shap_3rd.csv', encoding='cp949')\n",
    "X_test_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_test_shap_3rd.csv', encoding='cp949')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged feature selection by shap\n",
    "X_train_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_train_shap_merge.csv', encoding='cp949')\n",
    "X_test_select = pd.read_csv(os.path.abspath(\"../features\")+'/X_test_shap_merge.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y['age']\n",
    "\n",
    "# 학습데이터 70%, 평가데이터 30%로 데이터 분할\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_select, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀렉션 안한거\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'learning_rate': [0.1, 0.03, 0.003],\n",
    "    'max_depth': [-1, 3, 5],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "LGBMRegressor(max_depth=3, num_leaves=28)\n"
     ]
    }
   ],
   "source": [
    "rand_search = RandomizedSearchCV(LGBMRegressor(), param_distributions=params, \n",
    "                                 scoring='neg_root_mean_squared_error', n_iter=5, random_state=1)\n",
    "rand_search.fit(X_train, y_train)\n",
    "print(\"Best estimator:\\n{}\".format(rand_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.121734442621461\n"
     ]
    }
   ],
   "source": [
    "# LGBM\n",
    "model =LGBMRegressor(max_depth=3, n_estimators=200, num_leaves=28,random_state=100)\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "print(np.sqrt(mean_squared_error(y_valid, model.predict(X_valid))))\n",
    "\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.042343448708646\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "model = CatBoostRegressor(random_state=0)\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "print(np.sqrt(mean_squared_error(y_valid, model.predict(X_valid))))\n",
    "\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [0.05,0.1,1,5,8,10,12,15,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Ridge(alpha=20)\n"
     ]
    }
   ],
   "source": [
    "rand_search = RandomizedSearchCV(Ridge(), param_distributions=params, \n",
    "                                 scoring='neg_root_mean_squared_error', n_iter=5, random_state=1)\n",
    "rand_search.fit(X_train, y_train)\n",
    "print(\"Best estimator:\\n{}\".format(rand_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.500892098933921\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(alpha=20,random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(np.sqrt(mean_squared_error(y_valid, model.predict(X_valid))))\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(i, h_size, num_hidden, activation, lr):\n",
    "    model = tf.keras.Sequential()\n",
    "    for _ in range(num_hidden):\n",
    "        model.add(tf.keras.layers.Dense(h_size, activation=activation))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='mse', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),]\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n",
    "                 batch_size=128, epochs=300, callbacks=callbacks, shuffle=False, verbose=2)\n",
    "    \n",
    "    return min(hist.history['val_root_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "119/119 - 1s - loss: 42725.2539 - root_mean_squared_error: 206.7009 - val_loss: 416.3042 - val_root_mean_squared_error: 20.4035\n",
      "Epoch 2/300\n",
      "119/119 - 0s - loss: 426.6346 - root_mean_squared_error: 20.6551 - val_loss: 409.5042 - val_root_mean_squared_error: 20.2362\n",
      "Epoch 3/300\n",
      "119/119 - 0s - loss: 421.8242 - root_mean_squared_error: 20.5384 - val_loss: 404.9295 - val_root_mean_squared_error: 20.1229\n",
      "Epoch 4/300\n",
      "119/119 - 0s - loss: 416.7132 - root_mean_squared_error: 20.4136 - val_loss: 400.0155 - val_root_mean_squared_error: 20.0004\n",
      "Epoch 5/300\n",
      "119/119 - 0s - loss: 411.3111 - root_mean_squared_error: 20.2808 - val_loss: 394.8153 - val_root_mean_squared_error: 19.8700\n",
      "Epoch 6/300\n",
      "119/119 - 0s - loss: 405.6742 - root_mean_squared_error: 20.1414 - val_loss: 389.4109 - val_root_mean_squared_error: 19.7335\n",
      "Epoch 7/300\n",
      "119/119 - 0s - loss: 399.8659 - root_mean_squared_error: 19.9966 - val_loss: 383.8707 - val_root_mean_squared_error: 19.5926\n",
      "Epoch 8/300\n",
      "119/119 - 0s - loss: 393.9342 - root_mean_squared_error: 19.8478 - val_loss: 378.2278 - val_root_mean_squared_error: 19.4481\n",
      "Epoch 9/300\n",
      "119/119 - 0s - loss: 387.9043 - root_mean_squared_error: 19.6953 - val_loss: 372.4875 - val_root_mean_squared_error: 19.2999\n",
      "Epoch 10/300\n",
      "119/119 - 0s - loss: 381.7819 - root_mean_squared_error: 19.5392 - val_loss: 366.6432 - val_root_mean_squared_error: 19.1479\n",
      "Epoch 11/300\n",
      "119/119 - 0s - loss: 375.5601 - root_mean_squared_error: 19.3794 - val_loss: 360.6835 - val_root_mean_squared_error: 18.9917\n",
      "Epoch 12/300\n",
      "119/119 - 0s - loss: 369.2238 - root_mean_squared_error: 19.2152 - val_loss: 354.5926 - val_root_mean_squared_error: 18.8306\n",
      "Epoch 13/300\n",
      "119/119 - 0s - loss: 362.7563 - root_mean_squared_error: 19.0462 - val_loss: 348.3502 - val_root_mean_squared_error: 18.6641\n",
      "Epoch 14/300\n",
      "119/119 - 0s - loss: 356.1432 - root_mean_squared_error: 18.8718 - val_loss: 341.9369 - val_root_mean_squared_error: 18.4915\n",
      "Epoch 15/300\n",
      "119/119 - 0s - loss: 349.3739 - root_mean_squared_error: 18.6915 - val_loss: 335.3418 - val_root_mean_squared_error: 18.3123\n",
      "Epoch 16/300\n",
      "119/119 - 0s - loss: 342.4427 - root_mean_squared_error: 18.5052 - val_loss: 328.5692 - val_root_mean_squared_error: 18.1265\n",
      "Epoch 17/300\n",
      "119/119 - 0s - loss: 335.3480 - root_mean_squared_error: 18.3125 - val_loss: 321.6352 - val_root_mean_squared_error: 17.9342\n",
      "Epoch 18/300\n",
      "119/119 - 0s - loss: 328.0917 - root_mean_squared_error: 18.1133 - val_loss: 314.5596 - val_root_mean_squared_error: 17.7358\n",
      "Epoch 19/300\n",
      "119/119 - 0s - loss: 320.6787 - root_mean_squared_error: 17.9075 - val_loss: 307.3594 - val_root_mean_squared_error: 17.5317\n",
      "Epoch 20/300\n",
      "119/119 - 0s - loss: 313.1173 - root_mean_squared_error: 17.6951 - val_loss: 300.0426 - val_root_mean_squared_error: 17.3217\n",
      "Epoch 21/300\n",
      "119/119 - 0s - loss: 305.4210 - root_mean_squared_error: 17.4763 - val_loss: 292.6027 - val_root_mean_squared_error: 17.1056\n",
      "Epoch 22/300\n",
      "119/119 - 1s - loss: 297.6078 - root_mean_squared_error: 17.2513 - val_loss: 285.0219 - val_root_mean_squared_error: 16.8826\n",
      "Epoch 23/300\n",
      "119/119 - 0s - loss: 289.6973 - root_mean_squared_error: 17.0205 - val_loss: 277.2871 - val_root_mean_squared_error: 16.6519\n",
      "Epoch 24/300\n",
      "119/119 - 0s - loss: 281.7091 - root_mean_squared_error: 16.7842 - val_loss: 269.4135 - val_root_mean_squared_error: 16.4138\n",
      "Epoch 25/300\n",
      "119/119 - 0s - loss: 273.6630 - root_mean_squared_error: 16.5428 - val_loss: 261.4598 - val_root_mean_squared_error: 16.1697\n",
      "Epoch 26/300\n",
      "119/119 - 0s - loss: 265.5807 - root_mean_squared_error: 16.2966 - val_loss: 253.5095 - val_root_mean_squared_error: 15.9220\n",
      "Epoch 27/300\n",
      "119/119 - 0s - loss: 257.4834 - root_mean_squared_error: 16.0463 - val_loss: 245.6262 - val_root_mean_squared_error: 15.6725\n",
      "Epoch 28/300\n",
      "119/119 - 0s - loss: 249.3875 - root_mean_squared_error: 15.7920 - val_loss: 237.8218 - val_root_mean_squared_error: 15.4215\n",
      "Epoch 29/300\n",
      "119/119 - 0s - loss: 241.3000 - root_mean_squared_error: 15.5338 - val_loss: 230.0624 - val_root_mean_squared_error: 15.1678\n",
      "Epoch 30/300\n",
      "119/119 - 0s - loss: 233.2264 - root_mean_squared_error: 15.2718 - val_loss: 222.3199 - val_root_mean_squared_error: 14.9104\n",
      "Epoch 31/300\n",
      "119/119 - 0s - loss: 225.1888 - root_mean_squared_error: 15.0063 - val_loss: 214.6302 - val_root_mean_squared_error: 14.6503\n",
      "Epoch 32/300\n",
      "119/119 - 0s - loss: 217.2345 - root_mean_squared_error: 14.7389 - val_loss: 207.0590 - val_root_mean_squared_error: 14.3895\n",
      "Epoch 33/300\n",
      "119/119 - 0s - loss: 209.4166 - root_mean_squared_error: 14.4712 - val_loss: 199.6391 - val_root_mean_squared_error: 14.1294\n",
      "Epoch 34/300\n",
      "119/119 - 0s - loss: 201.7710 - root_mean_squared_error: 14.2046 - val_loss: 192.3688 - val_root_mean_squared_error: 13.8697\n",
      "Epoch 35/300\n",
      "119/119 - 0s - loss: 194.3178 - root_mean_squared_error: 13.9398 - val_loss: 185.2366 - val_root_mean_squared_error: 13.6102\n",
      "Epoch 36/300\n",
      "119/119 - 0s - loss: 187.0689 - root_mean_squared_error: 13.6773 - val_loss: 178.2821 - val_root_mean_squared_error: 13.3522\n",
      "Epoch 37/300\n",
      "119/119 - 0s - loss: 180.0267 - root_mean_squared_error: 13.4174 - val_loss: 171.6631 - val_root_mean_squared_error: 13.1020\n",
      "Epoch 38/300\n",
      "119/119 - 0s - loss: 173.1899 - root_mean_squared_error: 13.1602 - val_loss: 165.5376 - val_root_mean_squared_error: 12.8661\n",
      "Epoch 39/300\n",
      "119/119 - 0s - loss: 166.5738 - root_mean_squared_error: 12.9063 - val_loss: 159.8702 - val_root_mean_squared_error: 12.6440\n",
      "Epoch 40/300\n",
      "119/119 - 0s - loss: 160.2035 - root_mean_squared_error: 12.6572 - val_loss: 154.5263 - val_root_mean_squared_error: 12.4309\n",
      "Epoch 41/300\n",
      "119/119 - 0s - loss: 154.0858 - root_mean_squared_error: 12.4131 - val_loss: 149.3149 - val_root_mean_squared_error: 12.2194\n",
      "Epoch 42/300\n",
      "119/119 - 0s - loss: 148.2092 - root_mean_squared_error: 12.1741 - val_loss: 144.0872 - val_root_mean_squared_error: 12.0036\n",
      "Epoch 43/300\n",
      "119/119 - 0s - loss: 142.5827 - root_mean_squared_error: 11.9408 - val_loss: 139.0235 - val_root_mean_squared_error: 11.7908\n",
      "Epoch 44/300\n",
      "119/119 - 0s - loss: 137.2262 - root_mean_squared_error: 11.7144 - val_loss: 134.2106 - val_root_mean_squared_error: 11.5849\n",
      "Epoch 45/300\n",
      "119/119 - 0s - loss: 132.1021 - root_mean_squared_error: 11.4936 - val_loss: 129.4312 - val_root_mean_squared_error: 11.3768\n",
      "Epoch 46/300\n",
      "119/119 - 0s - loss: 127.1929 - root_mean_squared_error: 11.2780 - val_loss: 124.8703 - val_root_mean_squared_error: 11.1745\n",
      "Epoch 47/300\n",
      "119/119 - 0s - loss: 122.5738 - root_mean_squared_error: 11.0713 - val_loss: 120.8949 - val_root_mean_squared_error: 10.9952\n",
      "Epoch 48/300\n",
      "119/119 - 0s - loss: 118.2665 - root_mean_squared_error: 10.8750 - val_loss: 117.1946 - val_root_mean_squared_error: 10.8256\n",
      "Epoch 49/300\n",
      "119/119 - 0s - loss: 114.2361 - root_mean_squared_error: 10.6881 - val_loss: 113.2159 - val_root_mean_squared_error: 10.6403\n",
      "Epoch 50/300\n",
      "119/119 - 0s - loss: 110.4825 - root_mean_squared_error: 10.5111 - val_loss: 109.0190 - val_root_mean_squared_error: 10.4412\n",
      "Epoch 51/300\n",
      "119/119 - 0s - loss: 106.9838 - root_mean_squared_error: 10.3433 - val_loss: 105.1202 - val_root_mean_squared_error: 10.2528\n",
      "Epoch 52/300\n",
      "119/119 - 0s - loss: 103.7462 - root_mean_squared_error: 10.1856 - val_loss: 101.9902 - val_root_mean_squared_error: 10.0990\n",
      "Epoch 53/300\n",
      "119/119 - 0s - loss: 100.8131 - root_mean_squared_error: 10.0406 - val_loss: 99.4838 - val_root_mean_squared_error: 9.9742\n",
      "Epoch 54/300\n",
      "119/119 - 0s - loss: 98.1520 - root_mean_squared_error: 9.9072 - val_loss: 97.0619 - val_root_mean_squared_error: 9.8520\n",
      "Epoch 55/300\n",
      "119/119 - 0s - loss: 95.7474 - root_mean_squared_error: 9.7851 - val_loss: 94.5251 - val_root_mean_squared_error: 9.7224\n",
      "Epoch 56/300\n",
      "119/119 - 0s - loss: 93.6293 - root_mean_squared_error: 9.6762 - val_loss: 92.0461 - val_root_mean_squared_error: 9.5941\n",
      "Epoch 57/300\n",
      "119/119 - 0s - loss: 91.8143 - root_mean_squared_error: 9.5820 - val_loss: 89.8788 - val_root_mean_squared_error: 9.4804\n",
      "Epoch 58/300\n",
      "119/119 - 0s - loss: 90.2986 - root_mean_squared_error: 9.5026 - val_loss: 88.1983 - val_root_mean_squared_error: 9.3914\n",
      "Epoch 59/300\n",
      "119/119 - 0s - loss: 89.0212 - root_mean_squared_error: 9.4351 - val_loss: 86.9404 - val_root_mean_squared_error: 9.3242\n",
      "Epoch 60/300\n",
      "119/119 - 0s - loss: 87.9194 - root_mean_squared_error: 9.3765 - val_loss: 85.8298 - val_root_mean_squared_error: 9.2644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "119/119 - 0s - loss: 86.9534 - root_mean_squared_error: 9.3249 - val_loss: 84.7697 - val_root_mean_squared_error: 9.2070\n",
      "Epoch 62/300\n",
      "119/119 - 0s - loss: 86.0457 - root_mean_squared_error: 9.2761 - val_loss: 83.8716 - val_root_mean_squared_error: 9.1581\n",
      "Epoch 63/300\n",
      "119/119 - 0s - loss: 85.1491 - root_mean_squared_error: 9.2276 - val_loss: 83.2394 - val_root_mean_squared_error: 9.1236\n",
      "Epoch 64/300\n",
      "119/119 - 0s - loss: 84.2889 - root_mean_squared_error: 9.1809 - val_loss: 82.9532 - val_root_mean_squared_error: 9.1079\n",
      "Epoch 65/300\n",
      "119/119 - 0s - loss: 83.5123 - root_mean_squared_error: 9.1385 - val_loss: 83.0476 - val_root_mean_squared_error: 9.1130\n",
      "Epoch 66/300\n",
      "119/119 - 0s - loss: 82.8459 - root_mean_squared_error: 9.1020 - val_loss: 83.4497 - val_root_mean_squared_error: 9.1351\n",
      "Epoch 67/300\n",
      "119/119 - 0s - loss: 82.2891 - root_mean_squared_error: 9.0713 - val_loss: 83.9864 - val_root_mean_squared_error: 9.1644\n",
      "Epoch 68/300\n",
      "119/119 - 0s - loss: 81.8261 - root_mean_squared_error: 9.0458 - val_loss: 84.4775 - val_root_mean_squared_error: 9.1912\n",
      "Epoch 69/300\n",
      "119/119 - 0s - loss: 81.4404 - root_mean_squared_error: 9.0244 - val_loss: 84.8188 - val_root_mean_squared_error: 9.2097\n",
      "Epoch 1/300\n",
      "119/119 - 2s - loss: 94964.9297 - root_mean_squared_error: 308.1638 - val_loss: 413.3037 - val_root_mean_squared_error: 20.3299\n",
      "Epoch 2/300\n",
      "119/119 - 0s - loss: 418.3154 - root_mean_squared_error: 20.4528 - val_loss: 394.4453 - val_root_mean_squared_error: 19.8606\n",
      "Epoch 3/300\n",
      "119/119 - 0s - loss: 398.8387 - root_mean_squared_error: 19.9709 - val_loss: 376.0675 - val_root_mean_squared_error: 19.3925\n",
      "Epoch 4/300\n",
      "119/119 - 0s - loss: 380.2335 - root_mean_squared_error: 19.4996 - val_loss: 357.6509 - val_root_mean_squared_error: 18.9117\n",
      "Epoch 5/300\n",
      "119/119 - 0s - loss: 361.6595 - root_mean_squared_error: 19.0173 - val_loss: 339.4052 - val_root_mean_squared_error: 18.4230\n",
      "Epoch 6/300\n",
      "119/119 - 0s - loss: 342.3759 - root_mean_squared_error: 18.5034 - val_loss: 320.7072 - val_root_mean_squared_error: 17.9083\n",
      "Epoch 7/300\n",
      "119/119 - 0s - loss: 322.5896 - root_mean_squared_error: 17.9608 - val_loss: 301.5338 - val_root_mean_squared_error: 17.3647\n",
      "Epoch 8/300\n",
      "119/119 - 0s - loss: 302.6348 - root_mean_squared_error: 17.3964 - val_loss: 282.0987 - val_root_mean_squared_error: 16.7958\n",
      "Epoch 9/300\n",
      "119/119 - 0s - loss: 282.6409 - root_mean_squared_error: 16.8119 - val_loss: 263.4707 - val_root_mean_squared_error: 16.2318\n",
      "Epoch 10/300\n",
      "119/119 - 0s - loss: 262.8021 - root_mean_squared_error: 16.2112 - val_loss: 246.0174 - val_root_mean_squared_error: 15.6849\n",
      "Epoch 11/300\n",
      "119/119 - 0s - loss: 243.4028 - root_mean_squared_error: 15.6014 - val_loss: 229.0561 - val_root_mean_squared_error: 15.1346\n",
      "Epoch 12/300\n",
      "119/119 - 0s - loss: 224.6977 - root_mean_squared_error: 14.9899 - val_loss: 212.1166 - val_root_mean_squared_error: 14.5642\n",
      "Epoch 13/300\n",
      "119/119 - 0s - loss: 206.8777 - root_mean_squared_error: 14.3832 - val_loss: 195.7045 - val_root_mean_squared_error: 13.9894\n",
      "Epoch 14/300\n",
      "119/119 - 0s - loss: 190.1055 - root_mean_squared_error: 13.7879 - val_loss: 180.0665 - val_root_mean_squared_error: 13.4189\n",
      "Epoch 15/300\n",
      "119/119 - 0s - loss: 174.4183 - root_mean_squared_error: 13.2068 - val_loss: 165.6174 - val_root_mean_squared_error: 12.8692\n",
      "Epoch 16/300\n",
      "119/119 - 0s - loss: 160.0416 - root_mean_squared_error: 12.6508 - val_loss: 153.0514 - val_root_mean_squared_error: 12.3714\n",
      "Epoch 17/300\n",
      "119/119 - 0s - loss: 147.0614 - root_mean_squared_error: 12.1269 - val_loss: 141.0672 - val_root_mean_squared_error: 11.8772\n",
      "Epoch 18/300\n",
      "119/119 - 0s - loss: 135.4534 - root_mean_squared_error: 11.6384 - val_loss: 129.5114 - val_root_mean_squared_error: 11.3803\n",
      "Epoch 19/300\n",
      "119/119 - 0s - loss: 125.1899 - root_mean_squared_error: 11.1888 - val_loss: 119.5995 - val_root_mean_squared_error: 10.9362\n",
      "Epoch 20/300\n",
      "119/119 - 0s - loss: 116.2993 - root_mean_squared_error: 10.7842 - val_loss: 111.8751 - val_root_mean_squared_error: 10.5771\n",
      "Epoch 21/300\n",
      "119/119 - 0s - loss: 108.7395 - root_mean_squared_error: 10.4278 - val_loss: 105.2653 - val_root_mean_squared_error: 10.2599\n",
      "Epoch 22/300\n",
      "119/119 - 0s - loss: 102.3800 - root_mean_squared_error: 10.1183 - val_loss: 99.0866 - val_root_mean_squared_error: 9.9542\n",
      "Epoch 23/300\n",
      "119/119 - 0s - loss: 97.2210 - root_mean_squared_error: 9.8601 - val_loss: 93.8530 - val_root_mean_squared_error: 9.6878\n",
      "Epoch 24/300\n",
      "119/119 - 0s - loss: 93.2330 - root_mean_squared_error: 9.6557 - val_loss: 90.1289 - val_root_mean_squared_error: 9.4936\n",
      "Epoch 25/300\n",
      "119/119 - 0s - loss: 90.2589 - root_mean_squared_error: 9.5005 - val_loss: 87.4887 - val_root_mean_squared_error: 9.3535\n",
      "Epoch 26/300\n",
      "119/119 - 0s - loss: 88.0477 - root_mean_squared_error: 9.3834 - val_loss: 85.5871 - val_root_mean_squared_error: 9.2513\n",
      "Epoch 27/300\n",
      "119/119 - 0s - loss: 85.9343 - root_mean_squared_error: 9.2701 - val_loss: 86.8270 - val_root_mean_squared_error: 9.3181\n",
      "Epoch 28/300\n",
      "119/119 - 0s - loss: 84.1086 - root_mean_squared_error: 9.1711 - val_loss: 88.5717 - val_root_mean_squared_error: 9.4113\n",
      "Epoch 29/300\n",
      "119/119 - 0s - loss: 83.1821 - root_mean_squared_error: 9.1204 - val_loss: 85.6541 - val_root_mean_squared_error: 9.2550\n",
      "Epoch 30/300\n",
      "119/119 - 0s - loss: 82.4789 - root_mean_squared_error: 9.0818 - val_loss: 81.6112 - val_root_mean_squared_error: 9.0339\n",
      "Epoch 31/300\n",
      "119/119 - 0s - loss: 81.6935 - root_mean_squared_error: 9.0384 - val_loss: 79.9848 - val_root_mean_squared_error: 8.9434\n",
      "Epoch 32/300\n",
      "119/119 - 0s - loss: 80.6985 - root_mean_squared_error: 8.9832 - val_loss: 80.8995 - val_root_mean_squared_error: 8.9944\n",
      "Epoch 33/300\n",
      "119/119 - 0s - loss: 80.0916 - root_mean_squared_error: 8.9494 - val_loss: 80.6040 - val_root_mean_squared_error: 8.9780\n",
      "Epoch 34/300\n",
      "119/119 - 0s - loss: 80.0015 - root_mean_squared_error: 8.9444 - val_loss: 78.5248 - val_root_mean_squared_error: 8.8614\n",
      "Epoch 35/300\n",
      "119/119 - 0s - loss: 80.2980 - root_mean_squared_error: 8.9609 - val_loss: 79.1567 - val_root_mean_squared_error: 8.8970\n",
      "Epoch 36/300\n",
      "119/119 - 0s - loss: 80.7203 - root_mean_squared_error: 8.9844 - val_loss: 79.9580 - val_root_mean_squared_error: 8.9419\n",
      "Epoch 37/300\n",
      "119/119 - 0s - loss: 82.0189 - root_mean_squared_error: 9.0564 - val_loss: 77.3550 - val_root_mean_squared_error: 8.7952\n",
      "Epoch 38/300\n",
      "119/119 - 0s - loss: 83.2358 - root_mean_squared_error: 9.1234 - val_loss: 77.4595 - val_root_mean_squared_error: 8.8011\n",
      "Epoch 39/300\n",
      "119/119 - 0s - loss: 82.8357 - root_mean_squared_error: 9.1014 - val_loss: 77.1926 - val_root_mean_squared_error: 8.7859\n",
      "Epoch 40/300\n",
      "119/119 - 0s - loss: 83.0114 - root_mean_squared_error: 9.1111 - val_loss: 77.3657 - val_root_mean_squared_error: 8.7958\n",
      "Epoch 41/300\n",
      "119/119 - 0s - loss: 83.5249 - root_mean_squared_error: 9.1392 - val_loss: 76.7147 - val_root_mean_squared_error: 8.7587\n",
      "Epoch 42/300\n",
      "119/119 - 0s - loss: 86.0577 - root_mean_squared_error: 9.2767 - val_loss: 77.2276 - val_root_mean_squared_error: 8.7879\n",
      "Epoch 43/300\n",
      "119/119 - 0s - loss: 83.2113 - root_mean_squared_error: 9.1220 - val_loss: 76.3321 - val_root_mean_squared_error: 8.7368\n",
      "Epoch 44/300\n",
      "119/119 - 0s - loss: 83.4068 - root_mean_squared_error: 9.1327 - val_loss: 76.6248 - val_root_mean_squared_error: 8.7536\n",
      "Epoch 45/300\n",
      "119/119 - 0s - loss: 88.3708 - root_mean_squared_error: 9.4006 - val_loss: 83.9235 - val_root_mean_squared_error: 9.1610\n",
      "Epoch 46/300\n",
      "119/119 - 0s - loss: 93.0536 - root_mean_squared_error: 9.6464 - val_loss: 76.0772 - val_root_mean_squared_error: 8.7222\n",
      "Epoch 47/300\n",
      "119/119 - 0s - loss: 94.9216 - root_mean_squared_error: 9.7428 - val_loss: 89.5266 - val_root_mean_squared_error: 9.4619\n",
      "Epoch 48/300\n",
      "119/119 - 0s - loss: 99.1968 - root_mean_squared_error: 9.9598 - val_loss: 145.9915 - val_root_mean_squared_error: 12.0827\n",
      "Epoch 49/300\n",
      "119/119 - 0s - loss: 110.9983 - root_mean_squared_error: 10.5356 - val_loss: 173.9963 - val_root_mean_squared_error: 13.1908\n",
      "Epoch 50/300\n",
      "119/119 - 0s - loss: 117.3226 - root_mean_squared_error: 10.8316 - val_loss: 184.5555 - val_root_mean_squared_error: 13.5851\n",
      "Epoch 51/300\n",
      "119/119 - 0s - loss: 119.9654 - root_mean_squared_error: 10.9529 - val_loss: 187.0207 - val_root_mean_squared_error: 13.6756\n",
      "Epoch 1/300\n",
      "119/119 - 2s - loss: 21743.1875 - root_mean_squared_error: 147.4557 - val_loss: 371.4219 - val_root_mean_squared_error: 19.2723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300\n",
      "119/119 - 0s - loss: 541.6176 - root_mean_squared_error: 23.2727 - val_loss: 427.7203 - val_root_mean_squared_error: 20.6814\n",
      "Epoch 3/300\n",
      "119/119 - 0s - loss: 202.8277 - root_mean_squared_error: 14.2418 - val_loss: 160.3745 - val_root_mean_squared_error: 12.6639\n",
      "Epoch 4/300\n",
      "119/119 - 0s - loss: 176.4531 - root_mean_squared_error: 13.2836 - val_loss: 219.6918 - val_root_mean_squared_error: 14.8220\n",
      "Epoch 5/300\n",
      "119/119 - 0s - loss: 139.1396 - root_mean_squared_error: 11.7957 - val_loss: 796.7537 - val_root_mean_squared_error: 28.2268\n",
      "Epoch 6/300\n",
      "119/119 - 0s - loss: 163.2324 - root_mean_squared_error: 12.7762 - val_loss: 87.2617 - val_root_mean_squared_error: 9.3414\n",
      "Epoch 7/300\n",
      "119/119 - 0s - loss: 115.6737 - root_mean_squared_error: 10.7552 - val_loss: 89.4436 - val_root_mean_squared_error: 9.4575\n",
      "Epoch 8/300\n",
      "119/119 - 0s - loss: 111.9963 - root_mean_squared_error: 10.5828 - val_loss: 85.8809 - val_root_mean_squared_error: 9.2672\n",
      "Epoch 9/300\n",
      "119/119 - 0s - loss: 114.7483 - root_mean_squared_error: 10.7121 - val_loss: 83.2374 - val_root_mean_squared_error: 9.1235\n",
      "Epoch 10/300\n",
      "119/119 - 0s - loss: 106.2215 - root_mean_squared_error: 10.3064 - val_loss: 82.2284 - val_root_mean_squared_error: 9.0680\n",
      "Epoch 11/300\n",
      "119/119 - 0s - loss: 114.5025 - root_mean_squared_error: 10.7006 - val_loss: 83.6918 - val_root_mean_squared_error: 9.1483\n",
      "Epoch 12/300\n",
      "119/119 - 0s - loss: 107.9721 - root_mean_squared_error: 10.3910 - val_loss: 85.3082 - val_root_mean_squared_error: 9.2362\n",
      "Epoch 13/300\n",
      "119/119 - 0s - loss: 99.4858 - root_mean_squared_error: 9.9743 - val_loss: 82.0536 - val_root_mean_squared_error: 9.0583\n",
      "Epoch 14/300\n",
      "119/119 - 0s - loss: 104.8945 - root_mean_squared_error: 10.2418 - val_loss: 95.8981 - val_root_mean_squared_error: 9.7928\n",
      "Epoch 15/300\n",
      "119/119 - 0s - loss: 99.0827 - root_mean_squared_error: 9.9540 - val_loss: 82.6736 - val_root_mean_squared_error: 9.0925\n",
      "Epoch 16/300\n",
      "119/119 - 0s - loss: 96.9928 - root_mean_squared_error: 9.8485 - val_loss: 81.3257 - val_root_mean_squared_error: 9.0181\n",
      "Epoch 17/300\n",
      "119/119 - 0s - loss: 107.3189 - root_mean_squared_error: 10.3595 - val_loss: 82.3687 - val_root_mean_squared_error: 9.0757\n",
      "Epoch 18/300\n",
      "119/119 - 0s - loss: 99.7797 - root_mean_squared_error: 9.9890 - val_loss: 82.9109 - val_root_mean_squared_error: 9.1055\n",
      "Epoch 19/300\n",
      "119/119 - 0s - loss: 103.4209 - root_mean_squared_error: 10.1696 - val_loss: 81.9551 - val_root_mean_squared_error: 9.0529\n",
      "Epoch 20/300\n",
      "119/119 - 0s - loss: 98.4620 - root_mean_squared_error: 9.9228 - val_loss: 81.1853 - val_root_mean_squared_error: 9.0103\n",
      "Epoch 21/300\n",
      "119/119 - 0s - loss: 95.4901 - root_mean_squared_error: 9.7719 - val_loss: 143.0316 - val_root_mean_squared_error: 11.9596\n",
      "Epoch 22/300\n",
      "119/119 - 0s - loss: 103.8651 - root_mean_squared_error: 10.1914 - val_loss: 80.2850 - val_root_mean_squared_error: 8.9602\n",
      "Epoch 23/300\n",
      "119/119 - 0s - loss: 100.7164 - root_mean_squared_error: 10.0358 - val_loss: 114.5177 - val_root_mean_squared_error: 10.7013\n",
      "Epoch 24/300\n",
      "119/119 - 0s - loss: 95.6396 - root_mean_squared_error: 9.7795 - val_loss: 78.8220 - val_root_mean_squared_error: 8.8782\n",
      "Epoch 25/300\n",
      "119/119 - 0s - loss: 93.2800 - root_mean_squared_error: 9.6582 - val_loss: 81.4023 - val_root_mean_squared_error: 9.0223\n",
      "Epoch 26/300\n",
      "119/119 - 0s - loss: 104.0435 - root_mean_squared_error: 10.2002 - val_loss: 137.8057 - val_root_mean_squared_error: 11.7391\n",
      "Epoch 27/300\n",
      "119/119 - 0s - loss: 97.2813 - root_mean_squared_error: 9.8631 - val_loss: 84.8456 - val_root_mean_squared_error: 9.2112\n",
      "Epoch 28/300\n",
      "119/119 - 0s - loss: 89.9742 - root_mean_squared_error: 9.4855 - val_loss: 79.6908 - val_root_mean_squared_error: 8.9270\n",
      "Epoch 29/300\n",
      "119/119 - 0s - loss: 94.8630 - root_mean_squared_error: 9.7398 - val_loss: 89.0218 - val_root_mean_squared_error: 9.4351\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(3):\n",
    "    h_sizes = [ 8, 16,32,64]\n",
    "    h_size = np.random.choice(h_sizes)\n",
    "    num_hidden = np.random.randint(0, 3)\n",
    "    activation = np.random.choice(['relu'])\n",
    "    lr = 10 ** np.random.randint(-5, 0)\n",
    "\n",
    "    val_loss = experiment(i, h_size, num_hidden, activation, lr)\n",
    "    results.append({\n",
    "        'val_loss': val_loss,\n",
    "        'h_size': h_size,\n",
    "        'num_hidden': num_hidden,\n",
    "        'activation': activation,\n",
    "        'lr': lr\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 9.107863426208496,\n",
       "  'h_size': 8,\n",
       "  'num_hidden': 0,\n",
       "  'activation': 'relu',\n",
       "  'lr': 0.001},\n",
       " {'val_loss': 8.722222328186035,\n",
       "  'h_size': 16,\n",
       "  'num_hidden': 0,\n",
       "  'activation': 'relu',\n",
       "  'lr': 0.01},\n",
       " {'val_loss': 8.878175735473633,\n",
       "  'h_size': 64,\n",
       "  'num_hidden': 2,\n",
       "  'activation': 'relu',\n",
       "  'lr': 0.01}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 981)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                15712     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,729\n",
      "Trainable params: 15,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = keras.layers.Dense(16, activation='relu')(input) \n",
    "#함수모형의 API\n",
    "output = keras.layers.Dense(1, activation='linear')(x) \n",
    "#회귀문제  항등함수 회귀는 아웃풋 뉴런이 하나여야함\n",
    "model = keras.Model(input, output) \n",
    "#모델을 입력부터하지않고 X부터도 사용할 수 있음. 어디서부터 어디까지 모델로쓰겠다.\n",
    "\n",
    "model.summary() \n",
    "#파라미터가 학습해야할 웨이트 308*16+1=4944 파라미터가 클수록 시간이오래걸린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "119/119 - 2s - loss: 1019.6760 - root_mean_squared_error: 31.9324 - val_loss: 257.8133 - val_root_mean_squared_error: 16.0566\n",
      "Epoch 2/300\n",
      "119/119 - 0s - loss: 146.9853 - root_mean_squared_error: 12.1238 - val_loss: 125.0434 - val_root_mean_squared_error: 11.1823\n",
      "Epoch 3/300\n",
      "119/119 - 0s - loss: 99.2573 - root_mean_squared_error: 9.9628 - val_loss: 82.9322 - val_root_mean_squared_error: 9.1067\n",
      "Epoch 4/300\n",
      "119/119 - 0s - loss: 84.4959 - root_mean_squared_error: 9.1922 - val_loss: 81.2028 - val_root_mean_squared_error: 9.0113\n",
      "Epoch 5/300\n",
      "119/119 - 0s - loss: 80.9139 - root_mean_squared_error: 8.9952 - val_loss: 77.4805 - val_root_mean_squared_error: 8.8023\n",
      "Epoch 6/300\n",
      "119/119 - 0s - loss: 80.0741 - root_mean_squared_error: 8.9484 - val_loss: 77.9432 - val_root_mean_squared_error: 8.8285\n",
      "Epoch 7/300\n",
      "119/119 - 0s - loss: 84.3058 - root_mean_squared_error: 9.1818 - val_loss: 80.0346 - val_root_mean_squared_error: 8.9462\n",
      "Epoch 8/300\n",
      "119/119 - 0s - loss: 76.4897 - root_mean_squared_error: 8.7458 - val_loss: 81.8371 - val_root_mean_squared_error: 9.0464\n",
      "Epoch 9/300\n",
      "119/119 - 0s - loss: 74.4380 - root_mean_squared_error: 8.6277 - val_loss: 85.2629 - val_root_mean_squared_error: 9.2338\n",
      "Epoch 10/300\n",
      "119/119 - 0s - loss: 74.2866 - root_mean_squared_error: 8.6190 - val_loss: 91.2546 - val_root_mean_squared_error: 9.5527\n",
      "9.552729741233955\n"
     ]
    }
   ],
   "source": [
    "# loss, optimizer, metrics 설정 옵티마이저의 이름을쓰는건 \n",
    "#옵티마이저의 디폴트값으로만 쓸것이고 \n",
    "#함수로 쓸경우는 디폴트로 안하고 값을 바꾸겠다는것 .\n",
    "\n",
    "#model.compile(loss='mse', optimizer='adam', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='mse', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# batch size, epoch, 조기종료조건 등 설정\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),] \n",
    "#에퐄 돌렸음에도 불구하고 더이상 감소가없으면 스톱\n",
    "#[keras.callbacks.ModelCheckpoint(filepath='best_nn_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n",
    "                 batch_size=128, epochs=300, callbacks=callbacks, shuffle=False, verbose=2) #셔플 트루로하면 셔플하고함.\n",
    "##배치사이즈를 크게하면 한번에 확돌아가니까 .. 배치사이즈를 작게하면 웨이트갱신은 빨리일어나지만 에포크가 느림.\n",
    "##배치사이즈를 크게하면 크게할수록 좋긴한데 어느시점부터는 똑같다.\n",
    "\n",
    "model.save('nn_model_rid.h5')\n",
    "\n",
    "dnn_model = keras.models.load_model('nn_model_rid.h5')\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_valid, dnn_model.predict(X_valid).flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LGBMRegressor(max_depth=3, n_estimators=200, num_leaves=28, random_state=100),\n",
       " <catboost.core.CatBoostRegressor at 0x1bf15ba69a0>,\n",
       " Ridge(alpha=20, random_state=0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.820086424079358 1 1 1 7\n",
      "8.660172518294717 1 1 2 6\n",
      "8.527561670621994 1 1 3 5\n",
      "8.423543551429724 1 1 4 4\n",
      "8.34918690765286 1 1 5 3\n",
      "8.30528845876301 1 1 6 2\n",
      "8.292331929250958 1 1 7 1\n",
      "8.60485821309958 1 2 1 6\n",
      "8.467757055123078 1 2 2 5\n",
      "8.35932366369647 1 2 3 4\n",
      "8.280684320812492 1 2 4 3\n",
      "8.232692867502776 1 2 5 2\n",
      "8.215886376412907 1 2 6 1\n",
      "8.420461893802567 1 3 1 5\n",
      "8.30771723929669 1 3 2 4\n",
      "8.224853256140618 1 3 3 3\n",
      "8.172778889708766 1 3 4 2\n",
      "8.152084183658106 1 3 5 1\n",
      "8.268960442755079 1 4 1 4\n",
      "8.181953117148323 1 4 2 3\n",
      "8.12582704538908 1 4 3 2\n",
      "8.101224079535095 1 4 4 1\n",
      "8.152188049808998 1 5 1 3\n",
      "8.092062964729895 1 5 2 2\n",
      "8.063550960854597 1 5 3 1\n",
      "8.071652144437278 1 6 1 2\n",
      "8.039250218262154 1 6 2 1\n",
      "8.028443280451464 1 7 1 1\n",
      "8.609857560633227 2 1 1 6\n",
      "8.472866067850088 2 1 2 5\n",
      "8.364528047431945 2 1 3 4\n",
      "8.285967514019928 2 1 4 3\n",
      "8.238036426878184 2 1 5 2\n",
      "8.22127050759908 2 1 6 1\n",
      "8.424375919645406 2 2 1 5\n",
      "8.311713682588497 2 2 2 4\n",
      "8.228919563276346 2 2 3 3\n",
      "8.17690090262757 2 2 4 2\n",
      "8.156246539789084 2 2 5 1\n",
      "8.271729365039164 2 3 1 4\n",
      "8.18478125403605 2 3 2 3\n",
      "8.128704695969736 2 3 3 2\n",
      "8.104140542870264 2 3 4 1\n",
      "8.153762238135037 2 4 1 3\n",
      "8.093678963193346 2 4 2 2\n",
      "8.065202894003031 2 4 3 1\n",
      "8.071995152765254 2 5 1 2\n",
      "8.039624926969253 2 5 2 1\n",
      "8.027534345820332 2 6 1 1\n",
      "8.431400742874583 3 1 1 5\n",
      "8.318862943664517 3 1 2 4\n",
      "8.236170286827601 3 1 3 3\n",
      "8.184227494616598 3 1 4 2\n",
      "8.163621525960066 3 1 5 1\n",
      "8.277667805244333 3 2 1 4\n",
      "8.190812490989591 3 2 2 3\n",
      "8.134807472700794 3 2 3 2\n",
      "8.110291857342263 3 2 4 1\n",
      "8.158552873736225 3 3 1 3\n",
      "8.098535238810056 3 3 2 2\n",
      "8.070106508931282 3 3 3 1\n",
      "8.075587958325821 3 4 1 2\n",
      "8.043262496138434 3 4 2 1\n",
      "8.029893620724268 3 5 1 1\n",
      "8.286768949381312 4 1 1 4\n",
      "8.200039760245478 4 1 2 3\n",
      "8.144128125371145 4 1 3 2\n",
      "8.119670670961678 4 1 4 1\n",
      "8.166554296151265 4 2 1 3\n",
      "8.106625968316436 4 2 2 2\n",
      "8.078255884191812 4 2 3 1\n",
      "8.082426227313965 4 3 1 2\n",
      "8.050158502672675 4 3 2 1\n",
      "8.03551822646778 4 4 1 1\n",
      "8.17775708072502 5 1 1 3\n",
      "8.117941480883003 5 1 2 2\n",
      "8.08964121060932 5 1 3 1\n",
      "8.092501732357722 5 2 1 2\n",
      "8.06030458329235 5 2 2 1\n",
      "8.044401313744107 5 3 1 1\n",
      "8.105802401821622 6 1 1 2\n",
      "8.073688485051834 6 1 2 1\n",
      "8.056532104209868 6 2 1 1\n",
      "8.071895955516593 7 1 1 1\n",
      "8.027534345820332 [2, 6, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 최적의 가중치 찾기 \n",
    "weights = []\n",
    "rmse_best = 1000\n",
    "for i in range(1, 10, 1):\n",
    "    for j in range(1, 10, 1):\n",
    "        for k in range(1, 10, 1):\n",
    "            for l in range(1, 10, 1):\n",
    "                if (i+j+k+l) != 10:\n",
    "                    continue\n",
    "                pred = (models[0].predict(X_valid) * i + models[1].predict(X_valid) * j + models[2].predict(X_valid) * k+dnn_model.predict(X_valid).flatten() * l)/10\n",
    "                rmse = np.sqrt(mean_squared_error(y_valid, pred))\n",
    "                print(rmse, i,j,k,l)            \n",
    "                if rmse < rmse_best:\n",
    "                    weights = [i,j,k,l]\n",
    "                    rmse_best = rmse \n",
    "print(rmse_best, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.872792048017793\n"
     ]
    }
   ],
   "source": [
    "# Ensemble: 가중평균 \n",
    "weights = [0.2,0.6,0.1,0.1]\n",
    "pred = models[0].predict(X_valid) * weights[0] + models[1].predict(X_valid) * weights[1] + models[2].predict(X_valid) * weights[2] + dnn_model.predict(X_valid).flatten() * weights[3] \n",
    "print(np.sqrt(mean_squared_error(y_valid, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 데이터로 재학습 (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067435\n",
      "0:\tlearn: 10.2598393\ttotal: 380ms\tremaining: 6m 19s\n",
      "1:\tlearn: 10.0991043\ttotal: 764ms\tremaining: 6m 21s\n",
      "2:\tlearn: 9.9539631\ttotal: 1.18s\tremaining: 6m 31s\n",
      "3:\tlearn: 9.8112647\ttotal: 1.59s\tremaining: 6m 36s\n",
      "4:\tlearn: 9.6910135\ttotal: 2.07s\tremaining: 6m 51s\n",
      "5:\tlearn: 9.5767935\ttotal: 2.63s\tremaining: 7m 15s\n",
      "6:\tlearn: 9.4750804\ttotal: 3.19s\tremaining: 7m 32s\n",
      "7:\tlearn: 9.3735968\ttotal: 3.81s\tremaining: 7m 52s\n",
      "8:\tlearn: 9.2877464\ttotal: 4.46s\tremaining: 8m 10s\n",
      "9:\tlearn: 9.1978463\ttotal: 5.03s\tremaining: 8m 17s\n",
      "10:\tlearn: 9.1282181\ttotal: 5.53s\tremaining: 8m 17s\n",
      "11:\tlearn: 9.0615924\ttotal: 6.11s\tremaining: 8m 23s\n",
      "12:\tlearn: 9.0035142\ttotal: 6.76s\tremaining: 8m 33s\n",
      "13:\tlearn: 8.9443504\ttotal: 7.33s\tremaining: 8m 36s\n",
      "14:\tlearn: 8.8931415\ttotal: 7.73s\tremaining: 8m 27s\n",
      "15:\tlearn: 8.8486558\ttotal: 8.19s\tremaining: 8m 23s\n",
      "16:\tlearn: 8.8024656\ttotal: 8.59s\tremaining: 8m 16s\n",
      "17:\tlearn: 8.7612933\ttotal: 9.07s\tremaining: 8m 14s\n",
      "18:\tlearn: 8.7231669\ttotal: 9.45s\tremaining: 8m 7s\n",
      "19:\tlearn: 8.6879747\ttotal: 9.9s\tremaining: 8m 5s\n",
      "20:\tlearn: 8.6559749\ttotal: 10.3s\tremaining: 7m 59s\n",
      "21:\tlearn: 8.6209242\ttotal: 10.9s\tremaining: 8m 3s\n",
      "22:\tlearn: 8.5902703\ttotal: 11.4s\tremaining: 8m 4s\n",
      "23:\tlearn: 8.5567202\ttotal: 11.8s\tremaining: 8m\n",
      "24:\tlearn: 8.5329712\ttotal: 12.2s\tremaining: 7m 54s\n",
      "25:\tlearn: 8.5067424\ttotal: 12.6s\tremaining: 7m 52s\n",
      "26:\tlearn: 8.4810145\ttotal: 13s\tremaining: 7m 48s\n",
      "27:\tlearn: 8.4591814\ttotal: 13.3s\tremaining: 7m 43s\n",
      "28:\tlearn: 8.4377220\ttotal: 13.7s\tremaining: 7m 37s\n",
      "29:\tlearn: 8.4177745\ttotal: 14.1s\tremaining: 7m 34s\n",
      "30:\tlearn: 8.3979032\ttotal: 14.5s\tremaining: 7m 34s\n",
      "31:\tlearn: 8.3774933\ttotal: 15s\tremaining: 7m 32s\n",
      "32:\tlearn: 8.3617504\ttotal: 15.4s\tremaining: 7m 30s\n",
      "33:\tlearn: 8.3462407\ttotal: 15.7s\tremaining: 7m 27s\n",
      "34:\tlearn: 8.3313567\ttotal: 16.1s\tremaining: 7m 23s\n",
      "35:\tlearn: 8.3170263\ttotal: 16.5s\tremaining: 7m 20s\n",
      "36:\tlearn: 8.3027701\ttotal: 16.8s\tremaining: 7m 17s\n",
      "37:\tlearn: 8.2858949\ttotal: 17.2s\tremaining: 7m 15s\n",
      "38:\tlearn: 8.2741374\ttotal: 17.6s\tremaining: 7m 13s\n",
      "39:\tlearn: 8.2622249\ttotal: 18.4s\tremaining: 7m 21s\n",
      "40:\tlearn: 8.2507980\ttotal: 19.1s\tremaining: 7m 26s\n",
      "41:\tlearn: 8.2393327\ttotal: 19.6s\tremaining: 7m 28s\n",
      "42:\tlearn: 8.2252998\ttotal: 20.2s\tremaining: 7m 29s\n",
      "43:\tlearn: 8.2162743\ttotal: 20.7s\tremaining: 7m 30s\n",
      "44:\tlearn: 8.2060705\ttotal: 21.3s\tremaining: 7m 31s\n",
      "45:\tlearn: 8.1963624\ttotal: 21.8s\tremaining: 7m 32s\n",
      "46:\tlearn: 8.1885391\ttotal: 22.3s\tremaining: 7m 33s\n",
      "47:\tlearn: 8.1805233\ttotal: 22.9s\tremaining: 7m 33s\n",
      "48:\tlearn: 8.1718226\ttotal: 23.4s\tremaining: 7m 33s\n",
      "49:\tlearn: 8.1628863\ttotal: 23.8s\tremaining: 7m 32s\n",
      "50:\tlearn: 8.1561201\ttotal: 24.3s\tremaining: 7m 31s\n",
      "51:\tlearn: 8.1483325\ttotal: 24.8s\tremaining: 7m 31s\n",
      "52:\tlearn: 8.1417992\ttotal: 25.3s\tremaining: 7m 32s\n",
      "53:\tlearn: 8.1341811\ttotal: 25.9s\tremaining: 7m 33s\n",
      "54:\tlearn: 8.1254648\ttotal: 26.4s\tremaining: 7m 33s\n",
      "55:\tlearn: 8.1185536\ttotal: 26.9s\tremaining: 7m 33s\n",
      "56:\tlearn: 8.1117835\ttotal: 27.3s\tremaining: 7m 31s\n",
      "57:\tlearn: 8.1051707\ttotal: 27.6s\tremaining: 7m 28s\n",
      "58:\tlearn: 8.0974477\ttotal: 28s\tremaining: 7m 26s\n",
      "59:\tlearn: 8.0903761\ttotal: 28.3s\tremaining: 7m 23s\n",
      "60:\tlearn: 8.0858707\ttotal: 28.7s\tremaining: 7m 21s\n",
      "61:\tlearn: 8.0798648\ttotal: 29.1s\tremaining: 7m 19s\n",
      "62:\tlearn: 8.0734134\ttotal: 29.5s\tremaining: 7m 18s\n",
      "63:\tlearn: 8.0678391\ttotal: 29.8s\tremaining: 7m 15s\n",
      "64:\tlearn: 8.0616400\ttotal: 30.2s\tremaining: 7m 13s\n",
      "65:\tlearn: 8.0554950\ttotal: 30.5s\tremaining: 7m 11s\n",
      "66:\tlearn: 8.0493963\ttotal: 30.9s\tremaining: 7m 9s\n",
      "67:\tlearn: 8.0453199\ttotal: 31.2s\tremaining: 7m 7s\n",
      "68:\tlearn: 8.0401706\ttotal: 31.5s\tremaining: 7m 5s\n",
      "69:\tlearn: 8.0354334\ttotal: 31.9s\tremaining: 7m 3s\n",
      "70:\tlearn: 8.0305858\ttotal: 32.8s\tremaining: 7m 9s\n",
      "71:\tlearn: 8.0260102\ttotal: 33.7s\tremaining: 7m 13s\n",
      "72:\tlearn: 8.0225305\ttotal: 34.3s\tremaining: 7m 15s\n",
      "73:\tlearn: 8.0174648\ttotal: 34.9s\tremaining: 7m 16s\n",
      "74:\tlearn: 8.0123853\ttotal: 35.5s\tremaining: 7m 17s\n",
      "75:\tlearn: 8.0079629\ttotal: 36s\tremaining: 7m 17s\n",
      "76:\tlearn: 8.0042727\ttotal: 36.5s\tremaining: 7m 17s\n",
      "77:\tlearn: 7.9993990\ttotal: 37.3s\tremaining: 7m 20s\n",
      "78:\tlearn: 7.9956074\ttotal: 37.9s\tremaining: 7m 21s\n",
      "79:\tlearn: 7.9917538\ttotal: 38.5s\tremaining: 7m 22s\n",
      "80:\tlearn: 7.9875053\ttotal: 39.2s\tremaining: 7m 24s\n",
      "81:\tlearn: 7.9836125\ttotal: 39.8s\tremaining: 7m 25s\n",
      "82:\tlearn: 7.9778786\ttotal: 40.9s\tremaining: 7m 31s\n",
      "83:\tlearn: 7.9744508\ttotal: 41.7s\tremaining: 7m 35s\n",
      "84:\tlearn: 7.9691024\ttotal: 42.5s\tremaining: 7m 38s\n",
      "85:\tlearn: 7.9655585\ttotal: 43.1s\tremaining: 7m 38s\n",
      "86:\tlearn: 7.9612672\ttotal: 43.5s\tremaining: 7m 36s\n",
      "87:\tlearn: 7.9570792\ttotal: 44s\tremaining: 7m 35s\n",
      "88:\tlearn: 7.9543885\ttotal: 44.4s\tremaining: 7m 34s\n",
      "89:\tlearn: 7.9503416\ttotal: 44.9s\tremaining: 7m 33s\n",
      "90:\tlearn: 7.9469809\ttotal: 45.4s\tremaining: 7m 33s\n",
      "91:\tlearn: 7.9433339\ttotal: 45.8s\tremaining: 7m 31s\n",
      "92:\tlearn: 7.9383994\ttotal: 46.2s\tremaining: 7m 30s\n",
      "93:\tlearn: 7.9349729\ttotal: 46.7s\tremaining: 7m 29s\n",
      "94:\tlearn: 7.9314293\ttotal: 47.2s\tremaining: 7m 29s\n",
      "95:\tlearn: 7.9280315\ttotal: 47.5s\tremaining: 7m 27s\n",
      "96:\tlearn: 7.9239013\ttotal: 48s\tremaining: 7m 26s\n",
      "97:\tlearn: 7.9208381\ttotal: 48.3s\tremaining: 7m 24s\n",
      "98:\tlearn: 7.9174605\ttotal: 48.7s\tremaining: 7m 23s\n",
      "99:\tlearn: 7.9135034\ttotal: 49.1s\tremaining: 7m 22s\n",
      "100:\tlearn: 7.9094401\ttotal: 49.6s\tremaining: 7m 21s\n",
      "101:\tlearn: 7.9057685\ttotal: 50.1s\tremaining: 7m 20s\n",
      "102:\tlearn: 7.9022460\ttotal: 50.6s\tremaining: 7m 20s\n",
      "103:\tlearn: 7.8988217\ttotal: 51.1s\tremaining: 7m 20s\n",
      "104:\tlearn: 7.8946355\ttotal: 51.6s\tremaining: 7m 20s\n",
      "105:\tlearn: 7.8917797\ttotal: 52.1s\tremaining: 7m 19s\n",
      "106:\tlearn: 7.8883037\ttotal: 52.5s\tremaining: 7m 18s\n",
      "107:\tlearn: 7.8858406\ttotal: 53s\tremaining: 7m 17s\n",
      "108:\tlearn: 7.8825995\ttotal: 53.5s\tremaining: 7m 17s\n",
      "109:\tlearn: 7.8789945\ttotal: 53.9s\tremaining: 7m 15s\n",
      "110:\tlearn: 7.8756372\ttotal: 54.3s\tremaining: 7m 14s\n",
      "111:\tlearn: 7.8714378\ttotal: 54.7s\tremaining: 7m 13s\n",
      "112:\tlearn: 7.8689948\ttotal: 55.1s\tremaining: 7m 12s\n",
      "113:\tlearn: 7.8651083\ttotal: 55.6s\tremaining: 7m 11s\n",
      "114:\tlearn: 7.8620767\ttotal: 56.1s\tremaining: 7m 11s\n",
      "115:\tlearn: 7.8581897\ttotal: 56.7s\tremaining: 7m 11s\n",
      "116:\tlearn: 7.8551837\ttotal: 57.1s\tremaining: 7m 11s\n",
      "117:\tlearn: 7.8518804\ttotal: 57.6s\tremaining: 7m 10s\n",
      "118:\tlearn: 7.8488446\ttotal: 58s\tremaining: 7m 9s\n",
      "119:\tlearn: 7.8463248\ttotal: 58.5s\tremaining: 7m 9s\n",
      "120:\tlearn: 7.8429052\ttotal: 59s\tremaining: 7m 8s\n",
      "121:\tlearn: 7.8385338\ttotal: 59.4s\tremaining: 7m 7s\n",
      "122:\tlearn: 7.8342639\ttotal: 59.9s\tremaining: 7m 7s\n",
      "123:\tlearn: 7.8322054\ttotal: 1m\tremaining: 7m 6s\n",
      "124:\tlearn: 7.8284099\ttotal: 1m\tremaining: 7m 5s\n",
      "125:\tlearn: 7.8244957\ttotal: 1m 1s\tremaining: 7m 5s\n",
      "126:\tlearn: 7.8213900\ttotal: 1m 1s\tremaining: 7m 4s\n",
      "127:\tlearn: 7.8187126\ttotal: 1m 2s\tremaining: 7m 4s\n",
      "128:\tlearn: 7.8158327\ttotal: 1m 2s\tremaining: 7m 3s\n",
      "129:\tlearn: 7.8128248\ttotal: 1m 3s\tremaining: 7m 4s\n",
      "130:\tlearn: 7.8099106\ttotal: 1m 4s\tremaining: 7m 4s\n",
      "131:\tlearn: 7.8058596\ttotal: 1m 4s\tremaining: 7m 3s\n",
      "132:\tlearn: 7.8011917\ttotal: 1m 4s\tremaining: 7m 2s\n",
      "133:\tlearn: 7.7969993\ttotal: 1m 5s\tremaining: 7m 1s\n",
      "134:\tlearn: 7.7948344\ttotal: 1m 5s\tremaining: 7m\n",
      "135:\tlearn: 7.7924330\ttotal: 1m 6s\tremaining: 7m\n",
      "136:\tlearn: 7.7896480\ttotal: 1m 6s\tremaining: 6m 59s\n",
      "137:\tlearn: 7.7862315\ttotal: 1m 7s\tremaining: 6m 58s\n",
      "138:\tlearn: 7.7839516\ttotal: 1m 7s\tremaining: 6m 57s\n",
      "139:\tlearn: 7.7805736\ttotal: 1m 7s\tremaining: 6m 56s\n",
      "140:\tlearn: 7.7779007\ttotal: 1m 8s\tremaining: 6m 55s\n",
      "141:\tlearn: 7.7743224\ttotal: 1m 8s\tremaining: 6m 54s\n",
      "142:\tlearn: 7.7709388\ttotal: 1m 9s\tremaining: 6m 54s\n",
      "143:\tlearn: 7.7677401\ttotal: 1m 9s\tremaining: 6m 53s\n",
      "144:\tlearn: 7.7629941\ttotal: 1m 10s\tremaining: 6m 52s\n",
      "145:\tlearn: 7.7591498\ttotal: 1m 10s\tremaining: 6m 52s\n",
      "146:\tlearn: 7.7566253\ttotal: 1m 11s\tremaining: 6m 52s\n",
      "147:\tlearn: 7.7531810\ttotal: 1m 11s\tremaining: 6m 51s\n",
      "148:\tlearn: 7.7461079\ttotal: 1m 11s\tremaining: 6m 50s\n",
      "149:\tlearn: 7.7431552\ttotal: 1m 12s\tremaining: 6m 49s\n",
      "150:\tlearn: 7.7398171\ttotal: 1m 13s\tremaining: 6m 50s\n",
      "151:\tlearn: 7.7356814\ttotal: 1m 13s\tremaining: 6m 50s\n",
      "152:\tlearn: 7.7312639\ttotal: 1m 13s\tremaining: 6m 49s\n",
      "153:\tlearn: 7.7277497\ttotal: 1m 14s\tremaining: 6m 48s\n",
      "154:\tlearn: 7.7254860\ttotal: 1m 14s\tremaining: 6m 47s\n",
      "155:\tlearn: 7.7207741\ttotal: 1m 15s\tremaining: 6m 46s\n",
      "156:\tlearn: 7.7170545\ttotal: 1m 15s\tremaining: 6m 44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157:\tlearn: 7.7133831\ttotal: 1m 15s\tremaining: 6m 44s\n",
      "158:\tlearn: 7.7094083\ttotal: 1m 16s\tremaining: 6m 43s\n",
      "159:\tlearn: 7.7055137\ttotal: 1m 16s\tremaining: 6m 41s\n",
      "160:\tlearn: 7.7012192\ttotal: 1m 16s\tremaining: 6m 40s\n",
      "161:\tlearn: 7.6963214\ttotal: 1m 17s\tremaining: 6m 39s\n",
      "162:\tlearn: 7.6933276\ttotal: 1m 17s\tremaining: 6m 38s\n",
      "163:\tlearn: 7.6901599\ttotal: 1m 17s\tremaining: 6m 37s\n",
      "164:\tlearn: 7.6865541\ttotal: 1m 18s\tremaining: 6m 36s\n",
      "165:\tlearn: 7.6822228\ttotal: 1m 18s\tremaining: 6m 35s\n",
      "166:\tlearn: 7.6793972\ttotal: 1m 18s\tremaining: 6m 33s\n",
      "167:\tlearn: 7.6758877\ttotal: 1m 19s\tremaining: 6m 33s\n",
      "168:\tlearn: 7.6717790\ttotal: 1m 19s\tremaining: 6m 32s\n",
      "169:\tlearn: 7.6683312\ttotal: 1m 20s\tremaining: 6m 31s\n",
      "170:\tlearn: 7.6639369\ttotal: 1m 20s\tremaining: 6m 31s\n",
      "171:\tlearn: 7.6606873\ttotal: 1m 21s\tremaining: 6m 30s\n",
      "172:\tlearn: 7.6576642\ttotal: 1m 21s\tremaining: 6m 29s\n",
      "173:\tlearn: 7.6550059\ttotal: 1m 21s\tremaining: 6m 28s\n",
      "174:\tlearn: 7.6517972\ttotal: 1m 22s\tremaining: 6m 28s\n",
      "175:\tlearn: 7.6475962\ttotal: 1m 22s\tremaining: 6m 27s\n",
      "176:\tlearn: 7.6447886\ttotal: 1m 23s\tremaining: 6m 26s\n",
      "177:\tlearn: 7.6421042\ttotal: 1m 23s\tremaining: 6m 26s\n",
      "178:\tlearn: 7.6377333\ttotal: 1m 24s\tremaining: 6m 25s\n",
      "179:\tlearn: 7.6341258\ttotal: 1m 24s\tremaining: 6m 24s\n",
      "180:\tlearn: 7.6313538\ttotal: 1m 24s\tremaining: 6m 24s\n",
      "181:\tlearn: 7.6277361\ttotal: 1m 25s\tremaining: 6m 23s\n",
      "182:\tlearn: 7.6239391\ttotal: 1m 25s\tremaining: 6m 22s\n",
      "183:\tlearn: 7.6176974\ttotal: 1m 26s\tremaining: 6m 22s\n",
      "184:\tlearn: 7.6135085\ttotal: 1m 26s\tremaining: 6m 21s\n",
      "185:\tlearn: 7.6103470\ttotal: 1m 26s\tremaining: 6m 20s\n",
      "186:\tlearn: 7.6068187\ttotal: 1m 27s\tremaining: 6m 19s\n",
      "187:\tlearn: 7.6032535\ttotal: 1m 27s\tremaining: 6m 18s\n",
      "188:\tlearn: 7.6019458\ttotal: 1m 27s\tremaining: 6m 17s\n",
      "189:\tlearn: 7.5987576\ttotal: 1m 28s\tremaining: 6m 16s\n",
      "190:\tlearn: 7.5953768\ttotal: 1m 28s\tremaining: 6m 15s\n",
      "191:\tlearn: 7.5913470\ttotal: 1m 28s\tremaining: 6m 14s\n",
      "192:\tlearn: 7.5885156\ttotal: 1m 29s\tremaining: 6m 12s\n",
      "193:\tlearn: 7.5850166\ttotal: 1m 29s\tremaining: 6m 11s\n",
      "194:\tlearn: 7.5821863\ttotal: 1m 29s\tremaining: 6m 10s\n",
      "195:\tlearn: 7.5773275\ttotal: 1m 30s\tremaining: 6m 9s\n",
      "196:\tlearn: 7.5721851\ttotal: 1m 30s\tremaining: 6m 9s\n",
      "197:\tlearn: 7.5694671\ttotal: 1m 30s\tremaining: 6m 7s\n",
      "198:\tlearn: 7.5652249\ttotal: 1m 31s\tremaining: 6m 6s\n",
      "199:\tlearn: 7.5640655\ttotal: 1m 31s\tremaining: 6m 5s\n",
      "200:\tlearn: 7.5599552\ttotal: 1m 31s\tremaining: 6m 4s\n",
      "201:\tlearn: 7.5569590\ttotal: 1m 32s\tremaining: 6m 3s\n",
      "202:\tlearn: 7.5514907\ttotal: 1m 32s\tremaining: 6m 2s\n",
      "203:\tlearn: 7.5507747\ttotal: 1m 32s\tremaining: 6m 2s\n",
      "204:\tlearn: 7.5470066\ttotal: 1m 33s\tremaining: 6m 1s\n",
      "205:\tlearn: 7.5435065\ttotal: 1m 33s\tremaining: 6m 1s\n",
      "206:\tlearn: 7.5390617\ttotal: 1m 34s\tremaining: 6m\n",
      "207:\tlearn: 7.5361689\ttotal: 1m 34s\tremaining: 6m\n",
      "208:\tlearn: 7.5308614\ttotal: 1m 35s\tremaining: 6m\n",
      "209:\tlearn: 7.5268225\ttotal: 1m 35s\tremaining: 5m 59s\n",
      "210:\tlearn: 7.5237793\ttotal: 1m 36s\tremaining: 5m 58s\n",
      "211:\tlearn: 7.5195513\ttotal: 1m 36s\tremaining: 5m 58s\n",
      "212:\tlearn: 7.5166290\ttotal: 1m 36s\tremaining: 5m 58s\n",
      "213:\tlearn: 7.5123587\ttotal: 1m 37s\tremaining: 5m 57s\n",
      "214:\tlearn: 7.5094628\ttotal: 1m 37s\tremaining: 5m 56s\n",
      "215:\tlearn: 7.5052939\ttotal: 1m 38s\tremaining: 5m 56s\n",
      "216:\tlearn: 7.5022215\ttotal: 1m 38s\tremaining: 5m 55s\n",
      "217:\tlearn: 7.4980319\ttotal: 1m 38s\tremaining: 5m 54s\n",
      "218:\tlearn: 7.4936483\ttotal: 1m 39s\tremaining: 5m 54s\n",
      "219:\tlearn: 7.4909141\ttotal: 1m 39s\tremaining: 5m 54s\n",
      "220:\tlearn: 7.4877945\ttotal: 1m 40s\tremaining: 5m 53s\n",
      "221:\tlearn: 7.4852792\ttotal: 1m 40s\tremaining: 5m 53s\n",
      "222:\tlearn: 7.4812335\ttotal: 1m 41s\tremaining: 5m 52s\n",
      "223:\tlearn: 7.4799013\ttotal: 1m 41s\tremaining: 5m 51s\n",
      "224:\tlearn: 7.4754993\ttotal: 1m 41s\tremaining: 5m 50s\n",
      "225:\tlearn: 7.4718602\ttotal: 1m 42s\tremaining: 5m 50s\n",
      "226:\tlearn: 7.4686329\ttotal: 1m 42s\tremaining: 5m 49s\n",
      "227:\tlearn: 7.4655182\ttotal: 1m 42s\tremaining: 5m 48s\n",
      "228:\tlearn: 7.4614322\ttotal: 1m 43s\tremaining: 5m 47s\n",
      "229:\tlearn: 7.4583509\ttotal: 1m 43s\tremaining: 5m 46s\n",
      "230:\tlearn: 7.4554583\ttotal: 1m 44s\tremaining: 5m 46s\n",
      "231:\tlearn: 7.4517548\ttotal: 1m 44s\tremaining: 5m 45s\n",
      "232:\tlearn: 7.4474598\ttotal: 1m 44s\tremaining: 5m 44s\n",
      "233:\tlearn: 7.4435611\ttotal: 1m 44s\tremaining: 5m 43s\n",
      "234:\tlearn: 7.4416837\ttotal: 1m 45s\tremaining: 5m 42s\n",
      "235:\tlearn: 7.4380358\ttotal: 1m 45s\tremaining: 5m 41s\n",
      "236:\tlearn: 7.4355089\ttotal: 1m 45s\tremaining: 5m 40s\n",
      "237:\tlearn: 7.4313563\ttotal: 1m 46s\tremaining: 5m 40s\n",
      "238:\tlearn: 7.4282500\ttotal: 1m 46s\tremaining: 5m 39s\n",
      "239:\tlearn: 7.4277035\ttotal: 1m 46s\tremaining: 5m 38s\n",
      "240:\tlearn: 7.4251309\ttotal: 1m 47s\tremaining: 5m 37s\n",
      "241:\tlearn: 7.4212455\ttotal: 1m 47s\tremaining: 5m 37s\n",
      "242:\tlearn: 7.4177593\ttotal: 1m 48s\tremaining: 5m 36s\n",
      "243:\tlearn: 7.4142923\ttotal: 1m 48s\tremaining: 5m 36s\n",
      "244:\tlearn: 7.4110591\ttotal: 1m 48s\tremaining: 5m 35s\n",
      "245:\tlearn: 7.4084722\ttotal: 1m 49s\tremaining: 5m 35s\n",
      "246:\tlearn: 7.4060328\ttotal: 1m 49s\tremaining: 5m 34s\n",
      "247:\tlearn: 7.4024613\ttotal: 1m 50s\tremaining: 5m 34s\n",
      "248:\tlearn: 7.3996601\ttotal: 1m 50s\tremaining: 5m 33s\n",
      "249:\tlearn: 7.3975182\ttotal: 1m 51s\tremaining: 5m 33s\n",
      "250:\tlearn: 7.3935151\ttotal: 1m 51s\tremaining: 5m 33s\n",
      "251:\tlearn: 7.3896369\ttotal: 1m 52s\tremaining: 5m 33s\n",
      "252:\tlearn: 7.3864088\ttotal: 1m 52s\tremaining: 5m 33s\n",
      "253:\tlearn: 7.3837211\ttotal: 1m 53s\tremaining: 5m 32s\n",
      "254:\tlearn: 7.3804685\ttotal: 1m 53s\tremaining: 5m 32s\n",
      "255:\tlearn: 7.3783868\ttotal: 1m 54s\tremaining: 5m 32s\n",
      "256:\tlearn: 7.3746718\ttotal: 1m 54s\tremaining: 5m 32s\n",
      "257:\tlearn: 7.3716443\ttotal: 1m 55s\tremaining: 5m 31s\n",
      "258:\tlearn: 7.3712242\ttotal: 1m 55s\tremaining: 5m 30s\n",
      "259:\tlearn: 7.3685422\ttotal: 1m 56s\tremaining: 5m 30s\n",
      "260:\tlearn: 7.3644302\ttotal: 1m 56s\tremaining: 5m 30s\n",
      "261:\tlearn: 7.3616601\ttotal: 1m 56s\tremaining: 5m 29s\n",
      "262:\tlearn: 7.3577862\ttotal: 1m 57s\tremaining: 5m 28s\n",
      "263:\tlearn: 7.3538362\ttotal: 1m 57s\tremaining: 5m 27s\n",
      "264:\tlearn: 7.3510223\ttotal: 1m 57s\tremaining: 5m 27s\n",
      "265:\tlearn: 7.3473260\ttotal: 1m 58s\tremaining: 5m 26s\n",
      "266:\tlearn: 7.3431865\ttotal: 1m 58s\tremaining: 5m 25s\n",
      "267:\tlearn: 7.3404489\ttotal: 1m 58s\tremaining: 5m 24s\n",
      "268:\tlearn: 7.3371819\ttotal: 1m 59s\tremaining: 5m 24s\n",
      "269:\tlearn: 7.3336553\ttotal: 1m 59s\tremaining: 5m 23s\n",
      "270:\tlearn: 7.3309430\ttotal: 2m\tremaining: 5m 22s\n",
      "271:\tlearn: 7.3296479\ttotal: 2m\tremaining: 5m 22s\n",
      "272:\tlearn: 7.3270752\ttotal: 2m\tremaining: 5m 21s\n",
      "273:\tlearn: 7.3239463\ttotal: 2m 1s\tremaining: 5m 20s\n",
      "274:\tlearn: 7.3208521\ttotal: 2m 1s\tremaining: 5m 20s\n",
      "275:\tlearn: 7.3170469\ttotal: 2m 1s\tremaining: 5m 19s\n",
      "276:\tlearn: 7.3120819\ttotal: 2m 2s\tremaining: 5m 18s\n",
      "277:\tlearn: 7.3070845\ttotal: 2m 2s\tremaining: 5m 18s\n",
      "278:\tlearn: 7.3040671\ttotal: 2m 3s\tremaining: 5m 18s\n",
      "279:\tlearn: 7.3017385\ttotal: 2m 3s\tremaining: 5m 17s\n",
      "280:\tlearn: 7.2992994\ttotal: 2m 3s\tremaining: 5m 17s\n",
      "281:\tlearn: 7.2964202\ttotal: 2m 4s\tremaining: 5m 16s\n",
      "282:\tlearn: 7.2940092\ttotal: 2m 5s\tremaining: 5m 16s\n",
      "283:\tlearn: 7.2908505\ttotal: 2m 5s\tremaining: 5m 16s\n",
      "284:\tlearn: 7.2872543\ttotal: 2m 5s\tremaining: 5m 15s\n",
      "285:\tlearn: 7.2847638\ttotal: 2m 6s\tremaining: 5m 15s\n",
      "286:\tlearn: 7.2810720\ttotal: 2m 6s\tremaining: 5m 14s\n",
      "287:\tlearn: 7.2782142\ttotal: 2m 7s\tremaining: 5m 14s\n",
      "288:\tlearn: 7.2743283\ttotal: 2m 7s\tremaining: 5m 13s\n",
      "289:\tlearn: 7.2713973\ttotal: 2m 7s\tremaining: 5m 13s\n",
      "290:\tlearn: 7.2686791\ttotal: 2m 8s\tremaining: 5m 12s\n",
      "291:\tlearn: 7.2651305\ttotal: 2m 8s\tremaining: 5m 12s\n",
      "292:\tlearn: 7.2618505\ttotal: 2m 9s\tremaining: 5m 11s\n",
      "293:\tlearn: 7.2590581\ttotal: 2m 9s\tremaining: 5m 11s\n",
      "294:\tlearn: 7.2561009\ttotal: 2m 9s\tremaining: 5m 10s\n",
      "295:\tlearn: 7.2533441\ttotal: 2m 10s\tremaining: 5m 10s\n",
      "296:\tlearn: 7.2507415\ttotal: 2m 10s\tremaining: 5m 9s\n",
      "297:\tlearn: 7.2481721\ttotal: 2m 11s\tremaining: 5m 9s\n",
      "298:\tlearn: 7.2443503\ttotal: 2m 11s\tremaining: 5m 8s\n",
      "299:\tlearn: 7.2399382\ttotal: 2m 11s\tremaining: 5m 7s\n",
      "300:\tlearn: 7.2360491\ttotal: 2m 12s\tremaining: 5m 7s\n",
      "301:\tlearn: 7.2329890\ttotal: 2m 12s\tremaining: 5m 6s\n",
      "302:\tlearn: 7.2301001\ttotal: 2m 12s\tremaining: 5m 5s\n",
      "303:\tlearn: 7.2270661\ttotal: 2m 13s\tremaining: 5m 5s\n",
      "304:\tlearn: 7.2242404\ttotal: 2m 13s\tremaining: 5m 4s\n",
      "305:\tlearn: 7.2213857\ttotal: 2m 13s\tremaining: 5m 3s\n",
      "306:\tlearn: 7.2178665\ttotal: 2m 14s\tremaining: 5m 2s\n",
      "307:\tlearn: 7.2148942\ttotal: 2m 14s\tremaining: 5m 2s\n",
      "308:\tlearn: 7.2104944\ttotal: 2m 14s\tremaining: 5m 1s\n",
      "309:\tlearn: 7.2075990\ttotal: 2m 15s\tremaining: 5m 1s\n",
      "310:\tlearn: 7.2047398\ttotal: 2m 15s\tremaining: 5m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311:\tlearn: 7.2005897\ttotal: 2m 15s\tremaining: 4m 59s\n",
      "312:\tlearn: 7.1973376\ttotal: 2m 16s\tremaining: 4m 59s\n",
      "313:\tlearn: 7.1950892\ttotal: 2m 16s\tremaining: 4m 58s\n",
      "314:\tlearn: 7.1946469\ttotal: 2m 16s\tremaining: 4m 57s\n",
      "315:\tlearn: 7.1919754\ttotal: 2m 17s\tremaining: 4m 57s\n",
      "316:\tlearn: 7.1888704\ttotal: 2m 17s\tremaining: 4m 56s\n",
      "317:\tlearn: 7.1862663\ttotal: 2m 18s\tremaining: 4m 55s\n",
      "318:\tlearn: 7.1835799\ttotal: 2m 18s\tremaining: 4m 55s\n",
      "319:\tlearn: 7.1812712\ttotal: 2m 18s\tremaining: 4m 55s\n",
      "320:\tlearn: 7.1777470\ttotal: 2m 19s\tremaining: 4m 54s\n",
      "321:\tlearn: 7.1731863\ttotal: 2m 19s\tremaining: 4m 53s\n",
      "322:\tlearn: 7.1703291\ttotal: 2m 19s\tremaining: 4m 53s\n",
      "323:\tlearn: 7.1669601\ttotal: 2m 20s\tremaining: 4m 52s\n",
      "324:\tlearn: 7.1627497\ttotal: 2m 20s\tremaining: 4m 52s\n",
      "325:\tlearn: 7.1597739\ttotal: 2m 21s\tremaining: 4m 51s\n",
      "326:\tlearn: 7.1562639\ttotal: 2m 21s\tremaining: 4m 51s\n",
      "327:\tlearn: 7.1540420\ttotal: 2m 21s\tremaining: 4m 50s\n",
      "328:\tlearn: 7.1511498\ttotal: 2m 22s\tremaining: 4m 50s\n",
      "329:\tlearn: 7.1483614\ttotal: 2m 22s\tremaining: 4m 49s\n",
      "330:\tlearn: 7.1458998\ttotal: 2m 23s\tremaining: 4m 49s\n",
      "331:\tlearn: 7.1426354\ttotal: 2m 23s\tremaining: 4m 48s\n",
      "332:\tlearn: 7.1389574\ttotal: 2m 23s\tremaining: 4m 48s\n",
      "333:\tlearn: 7.1358113\ttotal: 2m 24s\tremaining: 4m 47s\n",
      "334:\tlearn: 7.1329906\ttotal: 2m 24s\tremaining: 4m 47s\n",
      "335:\tlearn: 7.1291467\ttotal: 2m 24s\tremaining: 4m 46s\n",
      "336:\tlearn: 7.1288196\ttotal: 2m 25s\tremaining: 4m 45s\n",
      "337:\tlearn: 7.1260304\ttotal: 2m 25s\tremaining: 4m 45s\n",
      "338:\tlearn: 7.1224353\ttotal: 2m 25s\tremaining: 4m 44s\n",
      "339:\tlearn: 7.1198155\ttotal: 2m 26s\tremaining: 4m 43s\n",
      "340:\tlearn: 7.1176900\ttotal: 2m 26s\tremaining: 4m 43s\n",
      "341:\tlearn: 7.1145712\ttotal: 2m 26s\tremaining: 4m 42s\n",
      "342:\tlearn: 7.1111470\ttotal: 2m 27s\tremaining: 4m 41s\n",
      "343:\tlearn: 7.1081763\ttotal: 2m 27s\tremaining: 4m 41s\n",
      "344:\tlearn: 7.1054294\ttotal: 2m 27s\tremaining: 4m 40s\n",
      "345:\tlearn: 7.1026418\ttotal: 2m 27s\tremaining: 4m 39s\n",
      "346:\tlearn: 7.0988840\ttotal: 2m 28s\tremaining: 4m 39s\n",
      "347:\tlearn: 7.0954892\ttotal: 2m 28s\tremaining: 4m 38s\n",
      "348:\tlearn: 7.0929975\ttotal: 2m 28s\tremaining: 4m 37s\n",
      "349:\tlearn: 7.0893881\ttotal: 2m 29s\tremaining: 4m 37s\n",
      "350:\tlearn: 7.0862334\ttotal: 2m 29s\tremaining: 4m 36s\n",
      "351:\tlearn: 7.0838099\ttotal: 2m 29s\tremaining: 4m 36s\n",
      "352:\tlearn: 7.0816801\ttotal: 2m 30s\tremaining: 4m 35s\n",
      "353:\tlearn: 7.0785024\ttotal: 2m 30s\tremaining: 4m 35s\n",
      "354:\tlearn: 7.0763718\ttotal: 2m 31s\tremaining: 4m 34s\n",
      "355:\tlearn: 7.0739191\ttotal: 2m 31s\tremaining: 4m 33s\n",
      "356:\tlearn: 7.0705854\ttotal: 2m 31s\tremaining: 4m 33s\n",
      "357:\tlearn: 7.0682179\ttotal: 2m 32s\tremaining: 4m 32s\n",
      "358:\tlearn: 7.0655891\ttotal: 2m 32s\tremaining: 4m 32s\n",
      "359:\tlearn: 7.0632455\ttotal: 2m 33s\tremaining: 4m 32s\n",
      "360:\tlearn: 7.0602144\ttotal: 2m 33s\tremaining: 4m 31s\n",
      "361:\tlearn: 7.0582856\ttotal: 2m 33s\tremaining: 4m 31s\n",
      "362:\tlearn: 7.0561100\ttotal: 2m 34s\tremaining: 4m 30s\n",
      "363:\tlearn: 7.0534910\ttotal: 2m 34s\tremaining: 4m 29s\n",
      "364:\tlearn: 7.0505088\ttotal: 2m 34s\tremaining: 4m 29s\n",
      "365:\tlearn: 7.0475380\ttotal: 2m 35s\tremaining: 4m 28s\n",
      "366:\tlearn: 7.0448658\ttotal: 2m 35s\tremaining: 4m 28s\n",
      "367:\tlearn: 7.0425411\ttotal: 2m 36s\tremaining: 4m 27s\n",
      "368:\tlearn: 7.0393022\ttotal: 2m 36s\tremaining: 4m 27s\n",
      "369:\tlearn: 7.0356807\ttotal: 2m 36s\tremaining: 4m 27s\n",
      "370:\tlearn: 7.0319549\ttotal: 2m 37s\tremaining: 4m 26s\n",
      "371:\tlearn: 7.0288689\ttotal: 2m 37s\tremaining: 4m 26s\n",
      "372:\tlearn: 7.0254694\ttotal: 2m 38s\tremaining: 4m 25s\n",
      "373:\tlearn: 7.0211697\ttotal: 2m 38s\tremaining: 4m 25s\n",
      "374:\tlearn: 7.0186285\ttotal: 2m 38s\tremaining: 4m 24s\n",
      "375:\tlearn: 7.0168840\ttotal: 2m 39s\tremaining: 4m 24s\n",
      "376:\tlearn: 7.0131436\ttotal: 2m 39s\tremaining: 4m 23s\n",
      "377:\tlearn: 7.0107987\ttotal: 2m 39s\tremaining: 4m 23s\n",
      "378:\tlearn: 7.0083884\ttotal: 2m 40s\tremaining: 4m 22s\n",
      "379:\tlearn: 7.0064493\ttotal: 2m 40s\tremaining: 4m 21s\n",
      "380:\tlearn: 7.0030566\ttotal: 2m 40s\tremaining: 4m 21s\n",
      "381:\tlearn: 7.0002390\ttotal: 2m 41s\tremaining: 4m 20s\n",
      "382:\tlearn: 6.9999437\ttotal: 2m 41s\tremaining: 4m 19s\n",
      "383:\tlearn: 6.9968594\ttotal: 2m 41s\tremaining: 4m 19s\n",
      "384:\tlearn: 6.9936246\ttotal: 2m 41s\tremaining: 4m 18s\n",
      "385:\tlearn: 6.9896980\ttotal: 2m 42s\tremaining: 4m 18s\n",
      "386:\tlearn: 6.9870542\ttotal: 2m 42s\tremaining: 4m 17s\n",
      "387:\tlearn: 6.9843535\ttotal: 2m 43s\tremaining: 4m 17s\n",
      "388:\tlearn: 6.9818921\ttotal: 2m 43s\tremaining: 4m 16s\n",
      "389:\tlearn: 6.9796315\ttotal: 2m 43s\tremaining: 4m 16s\n",
      "390:\tlearn: 6.9757479\ttotal: 2m 44s\tremaining: 4m 15s\n",
      "391:\tlearn: 6.9736248\ttotal: 2m 44s\tremaining: 4m 15s\n",
      "392:\tlearn: 6.9708065\ttotal: 2m 44s\tremaining: 4m 14s\n",
      "393:\tlearn: 6.9680128\ttotal: 2m 45s\tremaining: 4m 14s\n",
      "394:\tlearn: 6.9647251\ttotal: 2m 45s\tremaining: 4m 13s\n",
      "395:\tlearn: 6.9616011\ttotal: 2m 46s\tremaining: 4m 13s\n",
      "396:\tlearn: 6.9592121\ttotal: 2m 46s\tremaining: 4m 13s\n",
      "397:\tlearn: 6.9559902\ttotal: 2m 46s\tremaining: 4m 12s\n",
      "398:\tlearn: 6.9537630\ttotal: 2m 47s\tremaining: 4m 12s\n",
      "399:\tlearn: 6.9517323\ttotal: 2m 47s\tremaining: 4m 11s\n",
      "400:\tlearn: 6.9490403\ttotal: 2m 48s\tremaining: 4m 11s\n",
      "401:\tlearn: 6.9464610\ttotal: 2m 48s\tremaining: 4m 10s\n",
      "402:\tlearn: 6.9440568\ttotal: 2m 48s\tremaining: 4m 10s\n",
      "403:\tlearn: 6.9415534\ttotal: 2m 49s\tremaining: 4m 10s\n",
      "404:\tlearn: 6.9377683\ttotal: 2m 49s\tremaining: 4m 9s\n",
      "405:\tlearn: 6.9356488\ttotal: 2m 50s\tremaining: 4m 9s\n",
      "406:\tlearn: 6.9331132\ttotal: 2m 50s\tremaining: 4m 8s\n",
      "407:\tlearn: 6.9301142\ttotal: 2m 51s\tremaining: 4m 8s\n",
      "408:\tlearn: 6.9279668\ttotal: 2m 51s\tremaining: 4m 8s\n",
      "409:\tlearn: 6.9246950\ttotal: 2m 52s\tremaining: 4m 7s\n",
      "410:\tlearn: 6.9225415\ttotal: 2m 52s\tremaining: 4m 7s\n",
      "411:\tlearn: 6.9197089\ttotal: 2m 52s\tremaining: 4m 6s\n",
      "412:\tlearn: 6.9166818\ttotal: 2m 53s\tremaining: 4m 5s\n",
      "413:\tlearn: 6.9136602\ttotal: 2m 53s\tremaining: 4m 5s\n",
      "414:\tlearn: 6.9106859\ttotal: 2m 53s\tremaining: 4m 5s\n",
      "415:\tlearn: 6.9070471\ttotal: 2m 54s\tremaining: 4m 4s\n",
      "416:\tlearn: 6.9041006\ttotal: 2m 54s\tremaining: 4m 3s\n",
      "417:\tlearn: 6.9013880\ttotal: 2m 54s\tremaining: 4m 3s\n",
      "418:\tlearn: 6.8983419\ttotal: 2m 55s\tremaining: 4m 3s\n",
      "419:\tlearn: 6.8960812\ttotal: 2m 55s\tremaining: 4m 2s\n",
      "420:\tlearn: 6.8935443\ttotal: 2m 56s\tremaining: 4m 2s\n",
      "421:\tlearn: 6.8932888\ttotal: 2m 56s\tremaining: 4m 1s\n",
      "422:\tlearn: 6.8907292\ttotal: 2m 56s\tremaining: 4m 1s\n",
      "423:\tlearn: 6.8884285\ttotal: 2m 57s\tremaining: 4m\n",
      "424:\tlearn: 6.8860780\ttotal: 2m 57s\tremaining: 4m\n",
      "425:\tlearn: 6.8837339\ttotal: 2m 57s\tremaining: 3m 59s\n",
      "426:\tlearn: 6.8795295\ttotal: 2m 58s\tremaining: 3m 59s\n",
      "427:\tlearn: 6.8756430\ttotal: 2m 58s\tremaining: 3m 58s\n",
      "428:\tlearn: 6.8725997\ttotal: 2m 59s\tremaining: 3m 58s\n",
      "429:\tlearn: 6.8697229\ttotal: 2m 59s\tremaining: 3m 58s\n",
      "430:\tlearn: 6.8675637\ttotal: 3m\tremaining: 3m 57s\n",
      "431:\tlearn: 6.8641922\ttotal: 3m\tremaining: 3m 57s\n",
      "432:\tlearn: 6.8612895\ttotal: 3m 1s\tremaining: 3m 57s\n",
      "433:\tlearn: 6.8591364\ttotal: 3m 1s\tremaining: 3m 57s\n",
      "434:\tlearn: 6.8549337\ttotal: 3m 2s\tremaining: 3m 56s\n",
      "435:\tlearn: 6.8520402\ttotal: 3m 2s\tremaining: 3m 56s\n",
      "436:\tlearn: 6.8497860\ttotal: 3m 2s\tremaining: 3m 55s\n",
      "437:\tlearn: 6.8474693\ttotal: 3m 3s\tremaining: 3m 55s\n",
      "438:\tlearn: 6.8447683\ttotal: 3m 3s\tremaining: 3m 54s\n",
      "439:\tlearn: 6.8418006\ttotal: 3m 4s\tremaining: 3m 54s\n",
      "440:\tlearn: 6.8387097\ttotal: 3m 4s\tremaining: 3m 53s\n",
      "441:\tlearn: 6.8365166\ttotal: 3m 4s\tremaining: 3m 53s\n",
      "442:\tlearn: 6.8336239\ttotal: 3m 5s\tremaining: 3m 52s\n",
      "443:\tlearn: 6.8304797\ttotal: 3m 5s\tremaining: 3m 52s\n",
      "444:\tlearn: 6.8280404\ttotal: 3m 6s\tremaining: 3m 52s\n",
      "445:\tlearn: 6.8251777\ttotal: 3m 6s\tremaining: 3m 51s\n",
      "446:\tlearn: 6.8230353\ttotal: 3m 6s\tremaining: 3m 51s\n",
      "447:\tlearn: 6.8227595\ttotal: 3m 6s\tremaining: 3m 50s\n",
      "448:\tlearn: 6.8198305\ttotal: 3m 7s\tremaining: 3m 49s\n",
      "449:\tlearn: 6.8166411\ttotal: 3m 7s\tremaining: 3m 49s\n",
      "450:\tlearn: 6.8128746\ttotal: 3m 8s\tremaining: 3m 48s\n",
      "451:\tlearn: 6.8104694\ttotal: 3m 8s\tremaining: 3m 48s\n",
      "452:\tlearn: 6.8073763\ttotal: 3m 8s\tremaining: 3m 47s\n",
      "453:\tlearn: 6.8045259\ttotal: 3m 9s\tremaining: 3m 47s\n",
      "454:\tlearn: 6.8015802\ttotal: 3m 9s\tremaining: 3m 46s\n",
      "455:\tlearn: 6.7992711\ttotal: 3m 9s\tremaining: 3m 46s\n",
      "456:\tlearn: 6.7960543\ttotal: 3m 9s\tremaining: 3m 45s\n",
      "457:\tlearn: 6.7932949\ttotal: 3m 10s\tremaining: 3m 45s\n",
      "458:\tlearn: 6.7905818\ttotal: 3m 10s\tremaining: 3m 44s\n",
      "459:\tlearn: 6.7879639\ttotal: 3m 10s\tremaining: 3m 44s\n",
      "460:\tlearn: 6.7859366\ttotal: 3m 11s\tremaining: 3m 43s\n",
      "461:\tlearn: 6.7834963\ttotal: 3m 11s\tremaining: 3m 43s\n",
      "462:\tlearn: 6.7805029\ttotal: 3m 12s\tremaining: 3m 43s\n",
      "463:\tlearn: 6.7784451\ttotal: 3m 12s\tremaining: 3m 42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464:\tlearn: 6.7756298\ttotal: 3m 13s\tremaining: 3m 42s\n",
      "465:\tlearn: 6.7730110\ttotal: 3m 13s\tremaining: 3m 41s\n",
      "466:\tlearn: 6.7703487\ttotal: 3m 14s\tremaining: 3m 41s\n",
      "467:\tlearn: 6.7670765\ttotal: 3m 14s\tremaining: 3m 41s\n",
      "468:\tlearn: 6.7648965\ttotal: 3m 15s\tremaining: 3m 40s\n",
      "469:\tlearn: 6.7625945\ttotal: 3m 15s\tremaining: 3m 40s\n",
      "470:\tlearn: 6.7589949\ttotal: 3m 15s\tremaining: 3m 39s\n",
      "471:\tlearn: 6.7565980\ttotal: 3m 16s\tremaining: 3m 39s\n",
      "472:\tlearn: 6.7539541\ttotal: 3m 16s\tremaining: 3m 38s\n",
      "473:\tlearn: 6.7517990\ttotal: 3m 16s\tremaining: 3m 38s\n",
      "474:\tlearn: 6.7499847\ttotal: 3m 17s\tremaining: 3m 38s\n",
      "475:\tlearn: 6.7468226\ttotal: 3m 17s\tremaining: 3m 37s\n",
      "476:\tlearn: 6.7445137\ttotal: 3m 18s\tremaining: 3m 37s\n",
      "477:\tlearn: 6.7423956\ttotal: 3m 18s\tremaining: 3m 36s\n",
      "478:\tlearn: 6.7395059\ttotal: 3m 18s\tremaining: 3m 36s\n",
      "479:\tlearn: 6.7363160\ttotal: 3m 19s\tremaining: 3m 35s\n",
      "480:\tlearn: 6.7336468\ttotal: 3m 19s\tremaining: 3m 35s\n",
      "481:\tlearn: 6.7314159\ttotal: 3m 20s\tremaining: 3m 35s\n",
      "482:\tlearn: 6.7288130\ttotal: 3m 20s\tremaining: 3m 34s\n",
      "483:\tlearn: 6.7265391\ttotal: 3m 20s\tremaining: 3m 34s\n",
      "484:\tlearn: 6.7242926\ttotal: 3m 21s\tremaining: 3m 33s\n",
      "485:\tlearn: 6.7217972\ttotal: 3m 21s\tremaining: 3m 33s\n",
      "486:\tlearn: 6.7184719\ttotal: 3m 21s\tremaining: 3m 32s\n",
      "487:\tlearn: 6.7155664\ttotal: 3m 22s\tremaining: 3m 32s\n",
      "488:\tlearn: 6.7139649\ttotal: 3m 22s\tremaining: 3m 31s\n",
      "489:\tlearn: 6.7112995\ttotal: 3m 22s\tremaining: 3m 30s\n",
      "490:\tlearn: 6.7086673\ttotal: 3m 23s\tremaining: 3m 30s\n",
      "491:\tlearn: 6.7064924\ttotal: 3m 23s\tremaining: 3m 30s\n",
      "492:\tlearn: 6.7036273\ttotal: 3m 23s\tremaining: 3m 29s\n",
      "493:\tlearn: 6.7011692\ttotal: 3m 24s\tremaining: 3m 29s\n",
      "494:\tlearn: 6.6986527\ttotal: 3m 24s\tremaining: 3m 28s\n",
      "495:\tlearn: 6.6964813\ttotal: 3m 24s\tremaining: 3m 28s\n",
      "496:\tlearn: 6.6962012\ttotal: 3m 25s\tremaining: 3m 27s\n",
      "497:\tlearn: 6.6939319\ttotal: 3m 25s\tremaining: 3m 27s\n",
      "498:\tlearn: 6.6915297\ttotal: 3m 26s\tremaining: 3m 26s\n",
      "499:\tlearn: 6.6885863\ttotal: 3m 26s\tremaining: 3m 26s\n",
      "500:\tlearn: 6.6855765\ttotal: 3m 26s\tremaining: 3m 26s\n",
      "501:\tlearn: 6.6829293\ttotal: 3m 27s\tremaining: 3m 25s\n",
      "502:\tlearn: 6.6804344\ttotal: 3m 27s\tremaining: 3m 25s\n",
      "503:\tlearn: 6.6784214\ttotal: 3m 28s\tremaining: 3m 24s\n",
      "504:\tlearn: 6.6756878\ttotal: 3m 28s\tremaining: 3m 24s\n",
      "505:\tlearn: 6.6726997\ttotal: 3m 28s\tremaining: 3m 24s\n",
      "506:\tlearn: 6.6724854\ttotal: 3m 29s\tremaining: 3m 23s\n",
      "507:\tlearn: 6.6705818\ttotal: 3m 29s\tremaining: 3m 23s\n",
      "508:\tlearn: 6.6680797\ttotal: 3m 30s\tremaining: 3m 22s\n",
      "509:\tlearn: 6.6653496\ttotal: 3m 30s\tremaining: 3m 22s\n",
      "510:\tlearn: 6.6626803\ttotal: 3m 31s\tremaining: 3m 22s\n",
      "511:\tlearn: 6.6603401\ttotal: 3m 31s\tremaining: 3m 22s\n",
      "512:\tlearn: 6.6573530\ttotal: 3m 32s\tremaining: 3m 21s\n",
      "513:\tlearn: 6.6552548\ttotal: 3m 32s\tremaining: 3m 21s\n",
      "514:\tlearn: 6.6521594\ttotal: 3m 33s\tremaining: 3m 20s\n",
      "515:\tlearn: 6.6496160\ttotal: 3m 33s\tremaining: 3m 20s\n",
      "516:\tlearn: 6.6469103\ttotal: 3m 34s\tremaining: 3m 20s\n",
      "517:\tlearn: 6.6447761\ttotal: 3m 34s\tremaining: 3m 19s\n",
      "518:\tlearn: 6.6418245\ttotal: 3m 34s\tremaining: 3m 19s\n",
      "519:\tlearn: 6.6394414\ttotal: 3m 35s\tremaining: 3m 18s\n",
      "520:\tlearn: 6.6374019\ttotal: 3m 35s\tremaining: 3m 18s\n",
      "521:\tlearn: 6.6346913\ttotal: 3m 35s\tremaining: 3m 17s\n",
      "522:\tlearn: 6.6321285\ttotal: 3m 36s\tremaining: 3m 17s\n",
      "523:\tlearn: 6.6298597\ttotal: 3m 36s\tremaining: 3m 16s\n",
      "524:\tlearn: 6.6271091\ttotal: 3m 36s\tremaining: 3m 16s\n",
      "525:\tlearn: 6.6246654\ttotal: 3m 37s\tremaining: 3m 15s\n",
      "526:\tlearn: 6.6224704\ttotal: 3m 37s\tremaining: 3m 15s\n",
      "527:\tlearn: 6.6202277\ttotal: 3m 37s\tremaining: 3m 14s\n",
      "528:\tlearn: 6.6179261\ttotal: 3m 38s\tremaining: 3m 14s\n",
      "529:\tlearn: 6.6146740\ttotal: 3m 38s\tremaining: 3m 13s\n",
      "530:\tlearn: 6.6115052\ttotal: 3m 39s\tremaining: 3m 13s\n",
      "531:\tlearn: 6.6082247\ttotal: 3m 39s\tremaining: 3m 13s\n",
      "532:\tlearn: 6.6061187\ttotal: 3m 39s\tremaining: 3m 12s\n",
      "533:\tlearn: 6.6039595\ttotal: 3m 40s\tremaining: 3m 12s\n",
      "534:\tlearn: 6.6011798\ttotal: 3m 40s\tremaining: 3m 11s\n",
      "535:\tlearn: 6.5988087\ttotal: 3m 40s\tremaining: 3m 11s\n",
      "536:\tlearn: 6.5964723\ttotal: 3m 41s\tremaining: 3m 10s\n",
      "537:\tlearn: 6.5937490\ttotal: 3m 41s\tremaining: 3m 10s\n",
      "538:\tlearn: 6.5905518\ttotal: 3m 42s\tremaining: 3m 10s\n",
      "539:\tlearn: 6.5888062\ttotal: 3m 42s\tremaining: 3m 9s\n",
      "540:\tlearn: 6.5866166\ttotal: 3m 43s\tremaining: 3m 9s\n",
      "541:\tlearn: 6.5835700\ttotal: 3m 43s\tremaining: 3m 8s\n",
      "542:\tlearn: 6.5807433\ttotal: 3m 44s\tremaining: 3m 8s\n",
      "543:\tlearn: 6.5783386\ttotal: 3m 44s\tremaining: 3m 8s\n",
      "544:\tlearn: 6.5755505\ttotal: 3m 44s\tremaining: 3m 7s\n",
      "545:\tlearn: 6.5724840\ttotal: 3m 45s\tremaining: 3m 7s\n",
      "546:\tlearn: 6.5701968\ttotal: 3m 45s\tremaining: 3m 7s\n",
      "547:\tlearn: 6.5667919\ttotal: 3m 46s\tremaining: 3m 6s\n",
      "548:\tlearn: 6.5633003\ttotal: 3m 46s\tremaining: 3m 6s\n",
      "549:\tlearn: 6.5612891\ttotal: 3m 47s\tremaining: 3m 5s\n",
      "550:\tlearn: 6.5580160\ttotal: 3m 47s\tremaining: 3m 5s\n",
      "551:\tlearn: 6.5554485\ttotal: 3m 47s\tremaining: 3m 5s\n",
      "552:\tlearn: 6.5527001\ttotal: 3m 48s\tremaining: 3m 4s\n",
      "553:\tlearn: 6.5496787\ttotal: 3m 48s\tremaining: 3m 4s\n",
      "554:\tlearn: 6.5464999\ttotal: 3m 49s\tremaining: 3m 3s\n",
      "555:\tlearn: 6.5435717\ttotal: 3m 49s\tremaining: 3m 3s\n",
      "556:\tlearn: 6.5403740\ttotal: 3m 50s\tremaining: 3m 2s\n",
      "557:\tlearn: 6.5385604\ttotal: 3m 50s\tremaining: 3m 2s\n",
      "558:\tlearn: 6.5369058\ttotal: 3m 50s\tremaining: 3m 2s\n",
      "559:\tlearn: 6.5342962\ttotal: 3m 51s\tremaining: 3m 1s\n",
      "560:\tlearn: 6.5321451\ttotal: 3m 51s\tremaining: 3m 1s\n",
      "561:\tlearn: 6.5298394\ttotal: 3m 51s\tremaining: 3m\n",
      "562:\tlearn: 6.5271845\ttotal: 3m 52s\tremaining: 3m\n",
      "563:\tlearn: 6.5247944\ttotal: 3m 52s\tremaining: 2m 59s\n",
      "564:\tlearn: 6.5223010\ttotal: 3m 52s\tremaining: 2m 59s\n",
      "565:\tlearn: 6.5196984\ttotal: 3m 53s\tremaining: 2m 58s\n",
      "566:\tlearn: 6.5169029\ttotal: 3m 53s\tremaining: 2m 58s\n",
      "567:\tlearn: 6.5141372\ttotal: 3m 53s\tremaining: 2m 57s\n",
      "568:\tlearn: 6.5118613\ttotal: 3m 54s\tremaining: 2m 57s\n",
      "569:\tlearn: 6.5093878\ttotal: 3m 54s\tremaining: 2m 56s\n",
      "570:\tlearn: 6.5068933\ttotal: 3m 54s\tremaining: 2m 56s\n",
      "571:\tlearn: 6.5050066\ttotal: 3m 55s\tremaining: 2m 55s\n",
      "572:\tlearn: 6.5029600\ttotal: 3m 55s\tremaining: 2m 55s\n",
      "573:\tlearn: 6.5014988\ttotal: 3m 55s\tremaining: 2m 55s\n",
      "574:\tlearn: 6.4990683\ttotal: 3m 56s\tremaining: 2m 54s\n",
      "575:\tlearn: 6.4963955\ttotal: 3m 56s\tremaining: 2m 54s\n",
      "576:\tlearn: 6.4944878\ttotal: 3m 57s\tremaining: 2m 53s\n",
      "577:\tlearn: 6.4919068\ttotal: 3m 57s\tremaining: 2m 53s\n",
      "578:\tlearn: 6.4901643\ttotal: 3m 57s\tremaining: 2m 52s\n",
      "579:\tlearn: 6.4880669\ttotal: 3m 58s\tremaining: 2m 52s\n",
      "580:\tlearn: 6.4851103\ttotal: 3m 58s\tremaining: 2m 52s\n",
      "581:\tlearn: 6.4823765\ttotal: 3m 58s\tremaining: 2m 51s\n",
      "582:\tlearn: 6.4798169\ttotal: 3m 59s\tremaining: 2m 51s\n",
      "583:\tlearn: 6.4795856\ttotal: 3m 59s\tremaining: 2m 50s\n",
      "584:\tlearn: 6.4769404\ttotal: 4m\tremaining: 2m 50s\n",
      "585:\tlearn: 6.4749639\ttotal: 4m\tremaining: 2m 49s\n",
      "586:\tlearn: 6.4731100\ttotal: 4m\tremaining: 2m 49s\n",
      "587:\tlearn: 6.4708094\ttotal: 4m 1s\tremaining: 2m 48s\n",
      "588:\tlearn: 6.4676705\ttotal: 4m 1s\tremaining: 2m 48s\n",
      "589:\tlearn: 6.4659446\ttotal: 4m 1s\tremaining: 2m 48s\n",
      "590:\tlearn: 6.4637099\ttotal: 4m 2s\tremaining: 2m 47s\n",
      "591:\tlearn: 6.4617753\ttotal: 4m 2s\tremaining: 2m 47s\n",
      "592:\tlearn: 6.4595203\ttotal: 4m 3s\tremaining: 2m 46s\n",
      "593:\tlearn: 6.4565082\ttotal: 4m 3s\tremaining: 2m 46s\n",
      "594:\tlearn: 6.4536427\ttotal: 4m 3s\tremaining: 2m 45s\n",
      "595:\tlearn: 6.4510626\ttotal: 4m 3s\tremaining: 2m 45s\n",
      "596:\tlearn: 6.4477800\ttotal: 4m 4s\tremaining: 2m 44s\n",
      "597:\tlearn: 6.4454737\ttotal: 4m 4s\tremaining: 2m 44s\n",
      "598:\tlearn: 6.4428848\ttotal: 4m 4s\tremaining: 2m 43s\n",
      "599:\tlearn: 6.4398826\ttotal: 4m 5s\tremaining: 2m 43s\n",
      "600:\tlearn: 6.4381992\ttotal: 4m 5s\tremaining: 2m 42s\n",
      "601:\tlearn: 6.4354906\ttotal: 4m 5s\tremaining: 2m 42s\n",
      "602:\tlearn: 6.4334025\ttotal: 4m 6s\tremaining: 2m 42s\n",
      "603:\tlearn: 6.4313632\ttotal: 4m 6s\tremaining: 2m 41s\n",
      "604:\tlearn: 6.4295148\ttotal: 4m 6s\tremaining: 2m 41s\n",
      "605:\tlearn: 6.4274223\ttotal: 4m 7s\tremaining: 2m 40s\n",
      "606:\tlearn: 6.4257326\ttotal: 4m 7s\tremaining: 2m 40s\n",
      "607:\tlearn: 6.4223938\ttotal: 4m 7s\tremaining: 2m 39s\n",
      "608:\tlearn: 6.4202330\ttotal: 4m 7s\tremaining: 2m 39s\n",
      "609:\tlearn: 6.4178804\ttotal: 4m 8s\tremaining: 2m 38s\n",
      "610:\tlearn: 6.4158860\ttotal: 4m 8s\tremaining: 2m 38s\n",
      "611:\tlearn: 6.4120995\ttotal: 4m 9s\tremaining: 2m 37s\n",
      "612:\tlearn: 6.4098784\ttotal: 4m 9s\tremaining: 2m 37s\n",
      "613:\tlearn: 6.4069697\ttotal: 4m 9s\tremaining: 2m 37s\n",
      "614:\tlearn: 6.4041918\ttotal: 4m 10s\tremaining: 2m 36s\n",
      "615:\tlearn: 6.4019451\ttotal: 4m 10s\tremaining: 2m 36s\n",
      "616:\tlearn: 6.3989087\ttotal: 4m 10s\tremaining: 2m 35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617:\tlearn: 6.3958232\ttotal: 4m 11s\tremaining: 2m 35s\n",
      "618:\tlearn: 6.3928695\ttotal: 4m 11s\tremaining: 2m 34s\n",
      "619:\tlearn: 6.3911120\ttotal: 4m 12s\tremaining: 2m 34s\n",
      "620:\tlearn: 6.3892466\ttotal: 4m 12s\tremaining: 2m 34s\n",
      "621:\tlearn: 6.3866571\ttotal: 4m 12s\tremaining: 2m 33s\n",
      "622:\tlearn: 6.3847773\ttotal: 4m 13s\tremaining: 2m 33s\n",
      "623:\tlearn: 6.3825048\ttotal: 4m 13s\tremaining: 2m 32s\n",
      "624:\tlearn: 6.3798756\ttotal: 4m 13s\tremaining: 2m 32s\n",
      "625:\tlearn: 6.3772131\ttotal: 4m 14s\tremaining: 2m 31s\n",
      "626:\tlearn: 6.3740149\ttotal: 4m 14s\tremaining: 2m 31s\n",
      "627:\tlearn: 6.3722041\ttotal: 4m 15s\tremaining: 2m 31s\n",
      "628:\tlearn: 6.3699762\ttotal: 4m 15s\tremaining: 2m 30s\n",
      "629:\tlearn: 6.3678438\ttotal: 4m 15s\tremaining: 2m 30s\n",
      "630:\tlearn: 6.3656865\ttotal: 4m 16s\tremaining: 2m 29s\n",
      "631:\tlearn: 6.3636538\ttotal: 4m 16s\tremaining: 2m 29s\n",
      "632:\tlearn: 6.3607022\ttotal: 4m 16s\tremaining: 2m 28s\n",
      "633:\tlearn: 6.3582984\ttotal: 4m 17s\tremaining: 2m 28s\n",
      "634:\tlearn: 6.3565632\ttotal: 4m 17s\tremaining: 2m 27s\n",
      "635:\tlearn: 6.3542037\ttotal: 4m 17s\tremaining: 2m 27s\n",
      "636:\tlearn: 6.3523409\ttotal: 4m 18s\tremaining: 2m 27s\n",
      "637:\tlearn: 6.3501874\ttotal: 4m 18s\tremaining: 2m 26s\n",
      "638:\tlearn: 6.3481054\ttotal: 4m 18s\tremaining: 2m 26s\n",
      "639:\tlearn: 6.3453662\ttotal: 4m 18s\tremaining: 2m 25s\n",
      "640:\tlearn: 6.3433458\ttotal: 4m 19s\tremaining: 2m 25s\n",
      "641:\tlearn: 6.3413043\ttotal: 4m 19s\tremaining: 2m 24s\n",
      "642:\tlearn: 6.3391679\ttotal: 4m 19s\tremaining: 2m 24s\n",
      "643:\tlearn: 6.3370913\ttotal: 4m 20s\tremaining: 2m 23s\n",
      "644:\tlearn: 6.3342446\ttotal: 4m 20s\tremaining: 2m 23s\n",
      "645:\tlearn: 6.3323520\ttotal: 4m 20s\tremaining: 2m 22s\n",
      "646:\tlearn: 6.3302879\ttotal: 4m 21s\tremaining: 2m 22s\n",
      "647:\tlearn: 6.3268162\ttotal: 4m 21s\tremaining: 2m 22s\n",
      "648:\tlearn: 6.3242078\ttotal: 4m 21s\tremaining: 2m 21s\n",
      "649:\tlearn: 6.3224379\ttotal: 4m 22s\tremaining: 2m 21s\n",
      "650:\tlearn: 6.3200796\ttotal: 4m 22s\tremaining: 2m 20s\n",
      "651:\tlearn: 6.3173120\ttotal: 4m 22s\tremaining: 2m 20s\n",
      "652:\tlearn: 6.3150037\ttotal: 4m 23s\tremaining: 2m 19s\n",
      "653:\tlearn: 6.3127768\ttotal: 4m 23s\tremaining: 2m 19s\n",
      "654:\tlearn: 6.3104957\ttotal: 4m 24s\tremaining: 2m 19s\n",
      "655:\tlearn: 6.3073992\ttotal: 4m 24s\tremaining: 2m 18s\n",
      "656:\tlearn: 6.3042790\ttotal: 4m 24s\tremaining: 2m 18s\n",
      "657:\tlearn: 6.3020853\ttotal: 4m 25s\tremaining: 2m 17s\n",
      "658:\tlearn: 6.2999346\ttotal: 4m 25s\tremaining: 2m 17s\n",
      "659:\tlearn: 6.2997801\ttotal: 4m 26s\tremaining: 2m 17s\n",
      "660:\tlearn: 6.2980388\ttotal: 4m 26s\tremaining: 2m 16s\n",
      "661:\tlearn: 6.2966213\ttotal: 4m 26s\tremaining: 2m 16s\n",
      "662:\tlearn: 6.2943931\ttotal: 4m 27s\tremaining: 2m 15s\n",
      "663:\tlearn: 6.2913639\ttotal: 4m 27s\tremaining: 2m 15s\n",
      "664:\tlearn: 6.2883531\ttotal: 4m 28s\tremaining: 2m 15s\n",
      "665:\tlearn: 6.2852186\ttotal: 4m 28s\tremaining: 2m 14s\n",
      "666:\tlearn: 6.2829680\ttotal: 4m 28s\tremaining: 2m 14s\n",
      "667:\tlearn: 6.2802772\ttotal: 4m 29s\tremaining: 2m 13s\n",
      "668:\tlearn: 6.2781283\ttotal: 4m 29s\tremaining: 2m 13s\n",
      "669:\tlearn: 6.2766312\ttotal: 4m 29s\tremaining: 2m 12s\n",
      "670:\tlearn: 6.2743984\ttotal: 4m 30s\tremaining: 2m 12s\n",
      "671:\tlearn: 6.2724996\ttotal: 4m 30s\tremaining: 2m 12s\n",
      "672:\tlearn: 6.2702851\ttotal: 4m 30s\tremaining: 2m 11s\n",
      "673:\tlearn: 6.2677339\ttotal: 4m 31s\tremaining: 2m 11s\n",
      "674:\tlearn: 6.2648610\ttotal: 4m 31s\tremaining: 2m 10s\n",
      "675:\tlearn: 6.2618143\ttotal: 4m 31s\tremaining: 2m 10s\n",
      "676:\tlearn: 6.2588062\ttotal: 4m 32s\tremaining: 2m 9s\n",
      "677:\tlearn: 6.2562060\ttotal: 4m 32s\tremaining: 2m 9s\n",
      "678:\tlearn: 6.2543349\ttotal: 4m 32s\tremaining: 2m 8s\n",
      "679:\tlearn: 6.2511888\ttotal: 4m 33s\tremaining: 2m 8s\n",
      "680:\tlearn: 6.2492296\ttotal: 4m 33s\tremaining: 2m 8s\n",
      "681:\tlearn: 6.2475356\ttotal: 4m 33s\tremaining: 2m 7s\n",
      "682:\tlearn: 6.2446457\ttotal: 4m 33s\tremaining: 2m 7s\n",
      "683:\tlearn: 6.2432612\ttotal: 4m 34s\tremaining: 2m 6s\n",
      "684:\tlearn: 6.2410364\ttotal: 4m 34s\tremaining: 2m 6s\n",
      "685:\tlearn: 6.2382932\ttotal: 4m 34s\tremaining: 2m 5s\n",
      "686:\tlearn: 6.2366768\ttotal: 4m 35s\tremaining: 2m 5s\n",
      "687:\tlearn: 6.2351740\ttotal: 4m 35s\tremaining: 2m 5s\n",
      "688:\tlearn: 6.2321682\ttotal: 4m 36s\tremaining: 2m 4s\n",
      "689:\tlearn: 6.2303752\ttotal: 4m 36s\tremaining: 2m 4s\n",
      "690:\tlearn: 6.2270950\ttotal: 4m 36s\tremaining: 2m 3s\n",
      "691:\tlearn: 6.2249371\ttotal: 4m 37s\tremaining: 2m 3s\n",
      "692:\tlearn: 6.2234195\ttotal: 4m 37s\tremaining: 2m 3s\n",
      "693:\tlearn: 6.2207462\ttotal: 4m 38s\tremaining: 2m 2s\n",
      "694:\tlearn: 6.2187464\ttotal: 4m 38s\tremaining: 2m 2s\n",
      "695:\tlearn: 6.2163150\ttotal: 4m 39s\tremaining: 2m 1s\n",
      "696:\tlearn: 6.2142263\ttotal: 4m 39s\tremaining: 2m 1s\n",
      "697:\tlearn: 6.2121461\ttotal: 4m 39s\tremaining: 2m 1s\n",
      "698:\tlearn: 6.2099040\ttotal: 4m 40s\tremaining: 2m\n",
      "699:\tlearn: 6.2077447\ttotal: 4m 40s\tremaining: 2m\n",
      "700:\tlearn: 6.2045056\ttotal: 4m 41s\tremaining: 1m 59s\n",
      "701:\tlearn: 6.2023610\ttotal: 4m 41s\tremaining: 1m 59s\n",
      "702:\tlearn: 6.1998666\ttotal: 4m 41s\tremaining: 1m 59s\n",
      "703:\tlearn: 6.1979067\ttotal: 4m 42s\tremaining: 1m 58s\n",
      "704:\tlearn: 6.1968458\ttotal: 4m 42s\tremaining: 1m 58s\n",
      "705:\tlearn: 6.1946844\ttotal: 4m 42s\tremaining: 1m 57s\n",
      "706:\tlearn: 6.1923161\ttotal: 4m 43s\tremaining: 1m 57s\n",
      "707:\tlearn: 6.1901907\ttotal: 4m 43s\tremaining: 1m 56s\n",
      "708:\tlearn: 6.1882195\ttotal: 4m 43s\tremaining: 1m 56s\n",
      "709:\tlearn: 6.1867881\ttotal: 4m 44s\tremaining: 1m 56s\n",
      "710:\tlearn: 6.1849143\ttotal: 4m 44s\tremaining: 1m 55s\n",
      "711:\tlearn: 6.1816467\ttotal: 4m 44s\tremaining: 1m 55s\n",
      "712:\tlearn: 6.1797166\ttotal: 4m 45s\tremaining: 1m 54s\n",
      "713:\tlearn: 6.1768837\ttotal: 4m 45s\tremaining: 1m 54s\n",
      "714:\tlearn: 6.1751686\ttotal: 4m 45s\tremaining: 1m 53s\n",
      "715:\tlearn: 6.1728969\ttotal: 4m 45s\tremaining: 1m 53s\n",
      "716:\tlearn: 6.1706693\ttotal: 4m 46s\tremaining: 1m 52s\n",
      "717:\tlearn: 6.1694152\ttotal: 4m 46s\tremaining: 1m 52s\n",
      "718:\tlearn: 6.1692246\ttotal: 4m 46s\tremaining: 1m 52s\n",
      "719:\tlearn: 6.1672428\ttotal: 4m 47s\tremaining: 1m 51s\n",
      "720:\tlearn: 6.1651724\ttotal: 4m 47s\tremaining: 1m 51s\n",
      "721:\tlearn: 6.1627251\ttotal: 4m 47s\tremaining: 1m 50s\n",
      "722:\tlearn: 6.1602270\ttotal: 4m 48s\tremaining: 1m 50s\n",
      "723:\tlearn: 6.1580120\ttotal: 4m 48s\tremaining: 1m 49s\n",
      "724:\tlearn: 6.1559461\ttotal: 4m 48s\tremaining: 1m 49s\n",
      "725:\tlearn: 6.1532965\ttotal: 4m 49s\tremaining: 1m 49s\n",
      "726:\tlearn: 6.1510184\ttotal: 4m 49s\tremaining: 1m 48s\n",
      "727:\tlearn: 6.1488662\ttotal: 4m 50s\tremaining: 1m 48s\n",
      "728:\tlearn: 6.1453995\ttotal: 4m 50s\tremaining: 1m 47s\n",
      "729:\tlearn: 6.1429433\ttotal: 4m 50s\tremaining: 1m 47s\n",
      "730:\tlearn: 6.1413313\ttotal: 4m 51s\tremaining: 1m 47s\n",
      "731:\tlearn: 6.1392485\ttotal: 4m 51s\tremaining: 1m 46s\n",
      "732:\tlearn: 6.1363242\ttotal: 4m 51s\tremaining: 1m 46s\n",
      "733:\tlearn: 6.1345631\ttotal: 4m 52s\tremaining: 1m 45s\n",
      "734:\tlearn: 6.1312451\ttotal: 4m 52s\tremaining: 1m 45s\n",
      "735:\tlearn: 6.1296524\ttotal: 4m 53s\tremaining: 1m 45s\n",
      "736:\tlearn: 6.1275107\ttotal: 4m 53s\tremaining: 1m 44s\n",
      "737:\tlearn: 6.1243352\ttotal: 4m 53s\tremaining: 1m 44s\n",
      "738:\tlearn: 6.1217592\ttotal: 4m 54s\tremaining: 1m 43s\n",
      "739:\tlearn: 6.1182404\ttotal: 4m 54s\tremaining: 1m 43s\n",
      "740:\tlearn: 6.1150215\ttotal: 4m 55s\tremaining: 1m 43s\n",
      "741:\tlearn: 6.1130249\ttotal: 4m 55s\tremaining: 1m 42s\n",
      "742:\tlearn: 6.1112759\ttotal: 4m 55s\tremaining: 1m 42s\n",
      "743:\tlearn: 6.1095822\ttotal: 4m 56s\tremaining: 1m 41s\n",
      "744:\tlearn: 6.1065970\ttotal: 4m 56s\tremaining: 1m 41s\n",
      "745:\tlearn: 6.1045374\ttotal: 4m 56s\tremaining: 1m 41s\n",
      "746:\tlearn: 6.1015459\ttotal: 4m 57s\tremaining: 1m 40s\n",
      "747:\tlearn: 6.0988107\ttotal: 4m 57s\tremaining: 1m 40s\n",
      "748:\tlearn: 6.0964690\ttotal: 4m 57s\tremaining: 1m 39s\n",
      "749:\tlearn: 6.0946360\ttotal: 4m 57s\tremaining: 1m 39s\n",
      "750:\tlearn: 6.0926182\ttotal: 4m 58s\tremaining: 1m 38s\n",
      "751:\tlearn: 6.0905135\ttotal: 4m 58s\tremaining: 1m 38s\n",
      "752:\tlearn: 6.0880571\ttotal: 4m 58s\tremaining: 1m 38s\n",
      "753:\tlearn: 6.0860261\ttotal: 4m 59s\tremaining: 1m 37s\n",
      "754:\tlearn: 6.0843628\ttotal: 4m 59s\tremaining: 1m 37s\n",
      "755:\tlearn: 6.0825471\ttotal: 4m 59s\tremaining: 1m 36s\n",
      "756:\tlearn: 6.0802439\ttotal: 5m\tremaining: 1m 36s\n",
      "757:\tlearn: 6.0769882\ttotal: 5m\tremaining: 1m 35s\n",
      "758:\tlearn: 6.0744982\ttotal: 5m\tremaining: 1m 35s\n",
      "759:\tlearn: 6.0720653\ttotal: 5m\tremaining: 1m 35s\n",
      "760:\tlearn: 6.0707934\ttotal: 5m 1s\tremaining: 1m 34s\n",
      "761:\tlearn: 6.0679402\ttotal: 5m 1s\tremaining: 1m 34s\n",
      "762:\tlearn: 6.0661742\ttotal: 5m 2s\tremaining: 1m 33s\n",
      "763:\tlearn: 6.0636696\ttotal: 5m 2s\tremaining: 1m 33s\n",
      "764:\tlearn: 6.0608314\ttotal: 5m 2s\tremaining: 1m 33s\n",
      "765:\tlearn: 6.0584237\ttotal: 5m 3s\tremaining: 1m 32s\n",
      "766:\tlearn: 6.0570157\ttotal: 5m 3s\tremaining: 1m 32s\n",
      "767:\tlearn: 6.0547983\ttotal: 5m 3s\tremaining: 1m 31s\n",
      "768:\tlearn: 6.0532948\ttotal: 5m 4s\tremaining: 1m 31s\n",
      "769:\tlearn: 6.0517322\ttotal: 5m 4s\tremaining: 1m 31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770:\tlearn: 6.0486764\ttotal: 5m 5s\tremaining: 1m 30s\n",
      "771:\tlearn: 6.0468572\ttotal: 5m 5s\tremaining: 1m 30s\n",
      "772:\tlearn: 6.0452788\ttotal: 5m 5s\tremaining: 1m 29s\n",
      "773:\tlearn: 6.0434157\ttotal: 5m 6s\tremaining: 1m 29s\n",
      "774:\tlearn: 6.0408572\ttotal: 5m 6s\tremaining: 1m 29s\n",
      "775:\tlearn: 6.0391934\ttotal: 5m 6s\tremaining: 1m 28s\n",
      "776:\tlearn: 6.0370258\ttotal: 5m 7s\tremaining: 1m 28s\n",
      "777:\tlearn: 6.0349454\ttotal: 5m 7s\tremaining: 1m 27s\n",
      "778:\tlearn: 6.0329620\ttotal: 5m 8s\tremaining: 1m 27s\n",
      "779:\tlearn: 6.0307795\ttotal: 5m 8s\tremaining: 1m 27s\n",
      "780:\tlearn: 6.0280961\ttotal: 5m 9s\tremaining: 1m 26s\n",
      "781:\tlearn: 6.0261310\ttotal: 5m 9s\tremaining: 1m 26s\n",
      "782:\tlearn: 6.0240492\ttotal: 5m 9s\tremaining: 1m 25s\n",
      "783:\tlearn: 6.0220842\ttotal: 5m 9s\tremaining: 1m 25s\n",
      "784:\tlearn: 6.0193988\ttotal: 5m 10s\tremaining: 1m 24s\n",
      "785:\tlearn: 6.0173652\ttotal: 5m 10s\tremaining: 1m 24s\n",
      "786:\tlearn: 6.0154769\ttotal: 5m 10s\tremaining: 1m 24s\n",
      "787:\tlearn: 6.0133980\ttotal: 5m 11s\tremaining: 1m 23s\n",
      "788:\tlearn: 6.0112885\ttotal: 5m 11s\tremaining: 1m 23s\n",
      "789:\tlearn: 6.0096310\ttotal: 5m 11s\tremaining: 1m 22s\n",
      "790:\tlearn: 6.0080532\ttotal: 5m 12s\tremaining: 1m 22s\n",
      "791:\tlearn: 6.0061423\ttotal: 5m 12s\tremaining: 1m 22s\n",
      "792:\tlearn: 6.0046718\ttotal: 5m 12s\tremaining: 1m 21s\n",
      "793:\tlearn: 6.0016720\ttotal: 5m 13s\tremaining: 1m 21s\n",
      "794:\tlearn: 5.9992578\ttotal: 5m 13s\tremaining: 1m 20s\n",
      "795:\tlearn: 5.9966378\ttotal: 5m 13s\tremaining: 1m 20s\n",
      "796:\tlearn: 5.9948510\ttotal: 5m 13s\tremaining: 1m 19s\n",
      "797:\tlearn: 5.9946823\ttotal: 5m 14s\tremaining: 1m 19s\n",
      "798:\tlearn: 5.9933126\ttotal: 5m 14s\tremaining: 1m 19s\n",
      "799:\tlearn: 5.9914741\ttotal: 5m 14s\tremaining: 1m 18s\n",
      "800:\tlearn: 5.9890508\ttotal: 5m 15s\tremaining: 1m 18s\n",
      "801:\tlearn: 5.9872934\ttotal: 5m 15s\tremaining: 1m 17s\n",
      "802:\tlearn: 5.9854918\ttotal: 5m 16s\tremaining: 1m 17s\n",
      "803:\tlearn: 5.9839328\ttotal: 5m 16s\tremaining: 1m 17s\n",
      "804:\tlearn: 5.9824632\ttotal: 5m 16s\tremaining: 1m 16s\n",
      "805:\tlearn: 5.9802504\ttotal: 5m 17s\tremaining: 1m 16s\n",
      "806:\tlearn: 5.9774759\ttotal: 5m 17s\tremaining: 1m 15s\n",
      "807:\tlearn: 5.9749399\ttotal: 5m 17s\tremaining: 1m 15s\n",
      "808:\tlearn: 5.9720684\ttotal: 5m 18s\tremaining: 1m 15s\n",
      "809:\tlearn: 5.9706195\ttotal: 5m 18s\tremaining: 1m 14s\n",
      "810:\tlearn: 5.9688396\ttotal: 5m 19s\tremaining: 1m 14s\n",
      "811:\tlearn: 5.9668286\ttotal: 5m 19s\tremaining: 1m 13s\n",
      "812:\tlearn: 5.9646707\ttotal: 5m 19s\tremaining: 1m 13s\n",
      "813:\tlearn: 5.9629905\ttotal: 5m 20s\tremaining: 1m 13s\n",
      "814:\tlearn: 5.9602984\ttotal: 5m 20s\tremaining: 1m 12s\n",
      "815:\tlearn: 5.9576229\ttotal: 5m 21s\tremaining: 1m 12s\n",
      "816:\tlearn: 5.9561196\ttotal: 5m 21s\tremaining: 1m 12s\n",
      "817:\tlearn: 5.9537279\ttotal: 5m 21s\tremaining: 1m 11s\n",
      "818:\tlearn: 5.9513436\ttotal: 5m 22s\tremaining: 1m 11s\n",
      "819:\tlearn: 5.9491167\ttotal: 5m 22s\tremaining: 1m 10s\n",
      "820:\tlearn: 5.9472840\ttotal: 5m 23s\tremaining: 1m 10s\n",
      "821:\tlearn: 5.9447504\ttotal: 5m 23s\tremaining: 1m 10s\n",
      "822:\tlearn: 5.9437024\ttotal: 5m 23s\tremaining: 1m 9s\n",
      "823:\tlearn: 5.9413209\ttotal: 5m 23s\tremaining: 1m 9s\n",
      "824:\tlearn: 5.9389276\ttotal: 5m 24s\tremaining: 1m 8s\n",
      "825:\tlearn: 5.9366597\ttotal: 5m 24s\tremaining: 1m 8s\n",
      "826:\tlearn: 5.9340077\ttotal: 5m 24s\tremaining: 1m 7s\n",
      "827:\tlearn: 5.9318207\ttotal: 5m 25s\tremaining: 1m 7s\n",
      "828:\tlearn: 5.9299515\ttotal: 5m 25s\tremaining: 1m 7s\n",
      "829:\tlearn: 5.9281383\ttotal: 5m 25s\tremaining: 1m 6s\n",
      "830:\tlearn: 5.9261660\ttotal: 5m 26s\tremaining: 1m 6s\n",
      "831:\tlearn: 5.9239786\ttotal: 5m 26s\tremaining: 1m 5s\n",
      "832:\tlearn: 5.9219547\ttotal: 5m 26s\tremaining: 1m 5s\n",
      "833:\tlearn: 5.9199705\ttotal: 5m 26s\tremaining: 1m 5s\n",
      "834:\tlearn: 5.9169459\ttotal: 5m 27s\tremaining: 1m 4s\n",
      "835:\tlearn: 5.9154466\ttotal: 5m 27s\tremaining: 1m 4s\n",
      "836:\tlearn: 5.9126774\ttotal: 5m 27s\tremaining: 1m 3s\n",
      "837:\tlearn: 5.9112122\ttotal: 5m 28s\tremaining: 1m 3s\n",
      "838:\tlearn: 5.9087653\ttotal: 5m 28s\tremaining: 1m 3s\n",
      "839:\tlearn: 5.9071894\ttotal: 5m 28s\tremaining: 1m 2s\n",
      "840:\tlearn: 5.9051548\ttotal: 5m 29s\tremaining: 1m 2s\n",
      "841:\tlearn: 5.9032813\ttotal: 5m 29s\tremaining: 1m 1s\n",
      "842:\tlearn: 5.9018430\ttotal: 5m 30s\tremaining: 1m 1s\n",
      "843:\tlearn: 5.8994086\ttotal: 5m 30s\tremaining: 1m 1s\n",
      "844:\tlearn: 5.8974413\ttotal: 5m 30s\tremaining: 1m\n",
      "845:\tlearn: 5.8959478\ttotal: 5m 31s\tremaining: 1m\n",
      "846:\tlearn: 5.8929497\ttotal: 5m 31s\tremaining: 59.9s\n",
      "847:\tlearn: 5.8910237\ttotal: 5m 31s\tremaining: 59.5s\n",
      "848:\tlearn: 5.8886550\ttotal: 5m 32s\tremaining: 59.1s\n",
      "849:\tlearn: 5.8872186\ttotal: 5m 32s\tremaining: 58.7s\n",
      "850:\tlearn: 5.8845999\ttotal: 5m 33s\tremaining: 58.3s\n",
      "851:\tlearn: 5.8817115\ttotal: 5m 33s\tremaining: 57.9s\n",
      "852:\tlearn: 5.8799312\ttotal: 5m 33s\tremaining: 57.5s\n",
      "853:\tlearn: 5.8776856\ttotal: 5m 34s\tremaining: 57.1s\n",
      "854:\tlearn: 5.8755849\ttotal: 5m 34s\tremaining: 56.7s\n",
      "855:\tlearn: 5.8729736\ttotal: 5m 34s\tremaining: 56.3s\n",
      "856:\tlearn: 5.8710260\ttotal: 5m 35s\tremaining: 56s\n",
      "857:\tlearn: 5.8686319\ttotal: 5m 35s\tremaining: 55.6s\n",
      "858:\tlearn: 5.8670706\ttotal: 5m 36s\tremaining: 55.2s\n",
      "859:\tlearn: 5.8644578\ttotal: 5m 36s\tremaining: 54.8s\n",
      "860:\tlearn: 5.8625851\ttotal: 5m 36s\tremaining: 54.4s\n",
      "861:\tlearn: 5.8601019\ttotal: 5m 37s\tremaining: 54s\n",
      "862:\tlearn: 5.8588172\ttotal: 5m 37s\tremaining: 53.5s\n",
      "863:\tlearn: 5.8572725\ttotal: 5m 37s\tremaining: 53.1s\n",
      "864:\tlearn: 5.8549556\ttotal: 5m 37s\tremaining: 52.7s\n",
      "865:\tlearn: 5.8530718\ttotal: 5m 38s\tremaining: 52.3s\n",
      "866:\tlearn: 5.8513014\ttotal: 5m 38s\tremaining: 52s\n",
      "867:\tlearn: 5.8493811\ttotal: 5m 39s\tremaining: 51.6s\n",
      "868:\tlearn: 5.8476419\ttotal: 5m 39s\tremaining: 51.2s\n",
      "869:\tlearn: 5.8458316\ttotal: 5m 40s\tremaining: 50.8s\n",
      "870:\tlearn: 5.8431111\ttotal: 5m 40s\tremaining: 50.4s\n",
      "871:\tlearn: 5.8409443\ttotal: 5m 40s\tremaining: 50s\n",
      "872:\tlearn: 5.8384679\ttotal: 5m 41s\tremaining: 49.6s\n",
      "873:\tlearn: 5.8367773\ttotal: 5m 41s\tremaining: 49.3s\n",
      "874:\tlearn: 5.8339844\ttotal: 5m 42s\tremaining: 48.9s\n",
      "875:\tlearn: 5.8316292\ttotal: 5m 42s\tremaining: 48.5s\n",
      "876:\tlearn: 5.8294888\ttotal: 5m 43s\tremaining: 48.1s\n",
      "877:\tlearn: 5.8281844\ttotal: 5m 43s\tremaining: 47.7s\n",
      "878:\tlearn: 5.8262300\ttotal: 5m 43s\tremaining: 47.3s\n",
      "879:\tlearn: 5.8243891\ttotal: 5m 44s\tremaining: 47s\n",
      "880:\tlearn: 5.8223771\ttotal: 5m 44s\tremaining: 46.6s\n",
      "881:\tlearn: 5.8205037\ttotal: 5m 45s\tremaining: 46.2s\n",
      "882:\tlearn: 5.8173900\ttotal: 5m 45s\tremaining: 45.8s\n",
      "883:\tlearn: 5.8137896\ttotal: 5m 45s\tremaining: 45.4s\n",
      "884:\tlearn: 5.8121809\ttotal: 5m 46s\tremaining: 45s\n",
      "885:\tlearn: 5.8098505\ttotal: 5m 46s\tremaining: 44.6s\n",
      "886:\tlearn: 5.8080490\ttotal: 5m 47s\tremaining: 44.2s\n",
      "887:\tlearn: 5.8055661\ttotal: 5m 47s\tremaining: 43.8s\n",
      "888:\tlearn: 5.8022250\ttotal: 5m 47s\tremaining: 43.4s\n",
      "889:\tlearn: 5.8003304\ttotal: 5m 48s\tremaining: 43.1s\n",
      "890:\tlearn: 5.7993343\ttotal: 5m 48s\tremaining: 42.7s\n",
      "891:\tlearn: 5.7978221\ttotal: 5m 49s\tremaining: 42.3s\n",
      "892:\tlearn: 5.7943333\ttotal: 5m 49s\tremaining: 41.9s\n",
      "893:\tlearn: 5.7917826\ttotal: 5m 50s\tremaining: 41.5s\n",
      "894:\tlearn: 5.7900818\ttotal: 5m 50s\tremaining: 41.1s\n",
      "895:\tlearn: 5.7879033\ttotal: 5m 51s\tremaining: 40.8s\n",
      "896:\tlearn: 5.7864097\ttotal: 5m 51s\tremaining: 40.4s\n",
      "897:\tlearn: 5.7847512\ttotal: 5m 51s\tremaining: 40s\n",
      "898:\tlearn: 5.7826810\ttotal: 5m 52s\tremaining: 39.6s\n",
      "899:\tlearn: 5.7812501\ttotal: 5m 52s\tremaining: 39.2s\n",
      "900:\tlearn: 5.7795690\ttotal: 5m 52s\tremaining: 38.8s\n",
      "901:\tlearn: 5.7792286\ttotal: 5m 53s\tremaining: 38.4s\n",
      "902:\tlearn: 5.7773378\ttotal: 5m 53s\tremaining: 38s\n",
      "903:\tlearn: 5.7758367\ttotal: 5m 53s\tremaining: 37.6s\n",
      "904:\tlearn: 5.7744858\ttotal: 5m 53s\tremaining: 37.2s\n",
      "905:\tlearn: 5.7717629\ttotal: 5m 54s\tremaining: 36.8s\n",
      "906:\tlearn: 5.7699637\ttotal: 5m 54s\tremaining: 36.4s\n",
      "907:\tlearn: 5.7676819\ttotal: 5m 54s\tremaining: 36s\n",
      "908:\tlearn: 5.7649616\ttotal: 5m 55s\tremaining: 35.6s\n",
      "909:\tlearn: 5.7624598\ttotal: 5m 55s\tremaining: 35.2s\n",
      "910:\tlearn: 5.7607395\ttotal: 5m 56s\tremaining: 34.8s\n",
      "911:\tlearn: 5.7585245\ttotal: 5m 56s\tremaining: 34.4s\n",
      "912:\tlearn: 5.7569082\ttotal: 5m 56s\tremaining: 34s\n",
      "913:\tlearn: 5.7549389\ttotal: 5m 57s\tremaining: 33.6s\n",
      "914:\tlearn: 5.7529984\ttotal: 5m 57s\tremaining: 33.2s\n",
      "915:\tlearn: 5.7505531\ttotal: 5m 57s\tremaining: 32.8s\n",
      "916:\tlearn: 5.7488354\ttotal: 5m 58s\tremaining: 32.4s\n",
      "917:\tlearn: 5.7467893\ttotal: 5m 58s\tremaining: 32s\n",
      "918:\tlearn: 5.7440766\ttotal: 5m 59s\tremaining: 31.6s\n",
      "919:\tlearn: 5.7417111\ttotal: 5m 59s\tremaining: 31.3s\n",
      "920:\tlearn: 5.7389946\ttotal: 5m 59s\tremaining: 30.9s\n",
      "921:\tlearn: 5.7387609\ttotal: 6m\tremaining: 30.5s\n",
      "922:\tlearn: 5.7357500\ttotal: 6m\tremaining: 30.1s\n",
      "923:\tlearn: 5.7329059\ttotal: 6m 1s\tremaining: 29.7s\n",
      "924:\tlearn: 5.7307326\ttotal: 6m 1s\tremaining: 29.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925:\tlearn: 5.7287237\ttotal: 6m 1s\tremaining: 28.9s\n",
      "926:\tlearn: 5.7277231\ttotal: 6m 2s\tremaining: 28.5s\n",
      "927:\tlearn: 5.7258607\ttotal: 6m 2s\tremaining: 28.1s\n",
      "928:\tlearn: 5.7237969\ttotal: 6m 2s\tremaining: 27.7s\n",
      "929:\tlearn: 5.7217069\ttotal: 6m 3s\tremaining: 27.3s\n",
      "930:\tlearn: 5.7197822\ttotal: 6m 3s\tremaining: 27s\n",
      "931:\tlearn: 5.7167259\ttotal: 6m 4s\tremaining: 26.6s\n",
      "932:\tlearn: 5.7148958\ttotal: 6m 4s\tremaining: 26.2s\n",
      "933:\tlearn: 5.7131405\ttotal: 6m 4s\tremaining: 25.8s\n",
      "934:\tlearn: 5.7110762\ttotal: 6m 5s\tremaining: 25.4s\n",
      "935:\tlearn: 5.7091065\ttotal: 6m 5s\tremaining: 25s\n",
      "936:\tlearn: 5.7068293\ttotal: 6m 5s\tremaining: 24.6s\n",
      "937:\tlearn: 5.7049185\ttotal: 6m 6s\tremaining: 24.2s\n",
      "938:\tlearn: 5.7031109\ttotal: 6m 6s\tremaining: 23.8s\n",
      "939:\tlearn: 5.7016785\ttotal: 6m 6s\tremaining: 23.4s\n",
      "940:\tlearn: 5.6999794\ttotal: 6m 7s\tremaining: 23s\n",
      "941:\tlearn: 5.6980301\ttotal: 6m 7s\tremaining: 22.6s\n",
      "942:\tlearn: 5.6958635\ttotal: 6m 7s\tremaining: 22.2s\n",
      "943:\tlearn: 5.6942666\ttotal: 6m 7s\tremaining: 21.8s\n",
      "944:\tlearn: 5.6925945\ttotal: 6m 8s\tremaining: 21.4s\n",
      "945:\tlearn: 5.6912308\ttotal: 6m 8s\tremaining: 21s\n",
      "946:\tlearn: 5.6893053\ttotal: 6m 8s\tremaining: 20.6s\n",
      "947:\tlearn: 5.6880486\ttotal: 6m 9s\tremaining: 20.2s\n",
      "948:\tlearn: 5.6862483\ttotal: 6m 9s\tremaining: 19.9s\n",
      "949:\tlearn: 5.6838723\ttotal: 6m 9s\tremaining: 19.5s\n",
      "950:\tlearn: 5.6814011\ttotal: 6m 10s\tremaining: 19.1s\n",
      "951:\tlearn: 5.6790630\ttotal: 6m 10s\tremaining: 18.7s\n",
      "952:\tlearn: 5.6765866\ttotal: 6m 10s\tremaining: 18.3s\n",
      "953:\tlearn: 5.6745365\ttotal: 6m 11s\tremaining: 17.9s\n",
      "954:\tlearn: 5.6730271\ttotal: 6m 11s\tremaining: 17.5s\n",
      "955:\tlearn: 5.6712976\ttotal: 6m 12s\tremaining: 17.1s\n",
      "956:\tlearn: 5.6690214\ttotal: 6m 12s\tremaining: 16.7s\n",
      "957:\tlearn: 5.6661426\ttotal: 6m 12s\tremaining: 16.3s\n",
      "958:\tlearn: 5.6640931\ttotal: 6m 13s\tremaining: 16s\n",
      "959:\tlearn: 5.6636130\ttotal: 6m 13s\tremaining: 15.6s\n",
      "960:\tlearn: 5.6616013\ttotal: 6m 14s\tremaining: 15.2s\n",
      "961:\tlearn: 5.6592571\ttotal: 6m 14s\tremaining: 14.8s\n",
      "962:\tlearn: 5.6563385\ttotal: 6m 14s\tremaining: 14.4s\n",
      "963:\tlearn: 5.6543555\ttotal: 6m 15s\tremaining: 14s\n",
      "964:\tlearn: 5.6516671\ttotal: 6m 15s\tremaining: 13.6s\n",
      "965:\tlearn: 5.6499352\ttotal: 6m 16s\tremaining: 13.2s\n",
      "966:\tlearn: 5.6471809\ttotal: 6m 16s\tremaining: 12.8s\n",
      "967:\tlearn: 5.6441806\ttotal: 6m 16s\tremaining: 12.5s\n",
      "968:\tlearn: 5.6427238\ttotal: 6m 17s\tremaining: 12.1s\n",
      "969:\tlearn: 5.6405541\ttotal: 6m 17s\tremaining: 11.7s\n",
      "970:\tlearn: 5.6385868\ttotal: 6m 18s\tremaining: 11.3s\n",
      "971:\tlearn: 5.6364920\ttotal: 6m 18s\tremaining: 10.9s\n",
      "972:\tlearn: 5.6345090\ttotal: 6m 18s\tremaining: 10.5s\n",
      "973:\tlearn: 5.6321147\ttotal: 6m 19s\tremaining: 10.1s\n",
      "974:\tlearn: 5.6305516\ttotal: 6m 19s\tremaining: 9.73s\n",
      "975:\tlearn: 5.6283854\ttotal: 6m 19s\tremaining: 9.34s\n",
      "976:\tlearn: 5.6268083\ttotal: 6m 20s\tremaining: 8.95s\n",
      "977:\tlearn: 5.6250708\ttotal: 6m 20s\tremaining: 8.55s\n",
      "978:\tlearn: 5.6233885\ttotal: 6m 20s\tremaining: 8.16s\n",
      "979:\tlearn: 5.6206370\ttotal: 6m 20s\tremaining: 7.78s\n",
      "980:\tlearn: 5.6181165\ttotal: 6m 21s\tremaining: 7.38s\n",
      "981:\tlearn: 5.6157993\ttotal: 6m 21s\tremaining: 7s\n",
      "982:\tlearn: 5.6138757\ttotal: 6m 21s\tremaining: 6.61s\n",
      "983:\tlearn: 5.6119013\ttotal: 6m 22s\tremaining: 6.21s\n",
      "984:\tlearn: 5.6088312\ttotal: 6m 22s\tremaining: 5.83s\n",
      "985:\tlearn: 5.6065787\ttotal: 6m 22s\tremaining: 5.44s\n",
      "986:\tlearn: 5.6042819\ttotal: 6m 23s\tremaining: 5.05s\n",
      "987:\tlearn: 5.6037242\ttotal: 6m 23s\tremaining: 4.66s\n",
      "988:\tlearn: 5.6019897\ttotal: 6m 23s\tremaining: 4.27s\n",
      "989:\tlearn: 5.5994230\ttotal: 6m 24s\tremaining: 3.88s\n",
      "990:\tlearn: 5.5977355\ttotal: 6m 24s\tremaining: 3.49s\n",
      "991:\tlearn: 5.5958454\ttotal: 6m 25s\tremaining: 3.1s\n",
      "992:\tlearn: 5.5944215\ttotal: 6m 25s\tremaining: 2.72s\n",
      "993:\tlearn: 5.5924212\ttotal: 6m 25s\tremaining: 2.33s\n",
      "994:\tlearn: 5.5899992\ttotal: 6m 26s\tremaining: 1.94s\n",
      "995:\tlearn: 5.5880304\ttotal: 6m 26s\tremaining: 1.55s\n",
      "996:\tlearn: 5.5861932\ttotal: 6m 26s\tremaining: 1.16s\n",
      "997:\tlearn: 5.5845632\ttotal: 6m 27s\tremaining: 776ms\n",
      "998:\tlearn: 5.5824608\ttotal: 6m 27s\tremaining: 388ms\n",
      "999:\tlearn: 5.5803804\ttotal: 6m 28s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# 전체 학습데이터로 재학습\n",
    "for i, m in enumerate(models):\n",
    "    m.fit(X_train_select, y_train)\n",
    "    models[i] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " #X_test_select = X_test_select.fillna(X_test_select.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 예측모델\n",
    "pred = models[0].predict(X_test_select) * weights[0] + models[1].predict(X_test_select) * weights[1] + models[2].predict(X_test_select) * weights[2] +dnn_model.predict(X_test_select).flatten() * weights[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'submission_0615_2259.csv' is ready to submit.\n"
     ]
    }
   ],
   "source": [
    "t = pd.Timestamp.now()\n",
    "fname = f\"submission_{t.month:02}{t.day:02}_{t.hour:02}{t.minute:02}.csv\"\n",
    "submissions = pd.concat([pd.Series(IDtest, name=\"custid\"), pd.Series(pred, name=\"age\")] ,axis=1)\n",
    "submissions.to_csv(fname, index=False)\n",
    "print(\"'{}' is ready to submit.\" .format(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0614 21:04 -> 우리 features, 최종스코어 8.69730\n",
    "- 0614 20:02 -> 2등팀 features, 최종스코어 8.31725\n",
    "- 0615 16:57 -> 1등팀 features, shap 최종스코어 8.26823\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
